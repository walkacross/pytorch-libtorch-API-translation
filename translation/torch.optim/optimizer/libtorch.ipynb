{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7ac525",
   "metadata": {},
   "source": [
    "# How to use an optimizer\n",
    "To use torch.optim you have to construct an optimizer object, that will hold the current state and will update the parameters based on the computed gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5433d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pragma cling add_include_path(\"../../libtorch/include\")\n",
    "#pragma cling add_include_path(\"../../libtorch/include/torch/csrc/api/include\")\n",
    "#pragma cling add_library_path(\"../../libtorch/lib\")\n",
    "#pragma cling load(\"libtorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95cd044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <stdexcept>\n",
    "#include <string>\n",
    "#include <tuple>\n",
    "#include <memory>\n",
    "#include <utility>\n",
    "#include <torch/torch.h>\n",
    "#include <c10/util/flat_hash_map.h>\n",
    "namespace nn = torch::nn;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c2ab61",
   "metadata": {},
   "source": [
    "note: the grad of a parameter can be overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c34459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      " 2\n",
      "[ CPUFloatType{2} ]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor w = torch::tensor({1.0, 2.0}, torch::requires_grad());\n",
    "std::cout << w << std::endl;\n",
    "std::cout << w.requires_grad() << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d131f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.sum().backward();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850639d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      " 1\n",
      "[ CPUFloatType{2} ]"
     ]
    }
   ],
   "source": [
    "std::cout << w.grad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eae7f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto option = torch::optim::SGDOptions(0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac04672",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::optim::SGD oprimizer({w}, option);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50d98dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "oprimizer.step();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2b305c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9000\n",
      " 1.9000\n",
      "[ CPUFloatType{2} ]\n"
     ]
    }
   ],
   "source": [
    "std::cout << w << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db4750",
   "metadata": {},
   "source": [
    "## understand SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ac8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSGDOptimizer{\n",
    "    public:\n",
    "    torch::Tensor param;\n",
    "    float lr;\n",
    "    \n",
    "    CustomSGDOptimizer(torch::Tensor param, float lr):param(param), lr(lr){\n",
    "    }\n",
    "    \n",
    "    void step(){\n",
    "        {\n",
    "            torch::NoGradGuard no_grad;\n",
    "            param.data().add_(param.grad(), -1 * lr);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6450ad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      " 2\n",
      "[ CPUFloatType{2} ]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor custom_w = torch::tensor({1.0, 2.0}, torch::requires_grad());\n",
    "std::cout << custom_w << std::endl;\n",
    "std::cout << custom_w.requires_grad() << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd11b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_w.sum().backward();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31799e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      " 1\n",
      "[ CPUFloatType{2} ]"
     ]
    }
   ],
   "source": [
    "std::cout << custom_w.grad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eb43c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomSGDOptimizer custom_optimizer(custom_w, 0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6cae840",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_optimizer.step();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8df0e655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9000\n",
      " 1.9000\n",
      "[ CPUFloatType{2} ]\n"
     ]
    }
   ],
   "source": [
    "std::cout << custom_w << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a76b0",
   "metadata": {},
   "source": [
    "# understand Optimizer source code\n",
    "https://github.com/pytorch/pytorch/blob/master/torch/csrc/api/include/torch/optim/optimizer.h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6948795",
   "metadata": {},
   "source": [
    "### 1 OptimizerParamState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d23f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerParamState {\n",
    " public:\n",
    "  virtual std::unique_ptr<OptimizerParamState> clone() const;\n",
    "  virtual void serialize(torch::serialize::InputArchive& archive);\n",
    "  virtual void serialize(torch::serialize::OutputArchive& archive) const;\n",
    "  virtual ~OptimizerParamState() = default;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cf85f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::unique_ptr<OptimizerParamState> OptimizerParamState::clone() const {\n",
    "      throw std::runtime_error(\"clone() has not been implemented for torch::optim::OptimizerParamState. \");\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "609f5f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "void OptimizerParamState::serialize(torch::serialize::InputArchive& archive) {\n",
    "  throw std::runtime_error(\"void serialize(torch::serialize::InputArchive& archive) has not been implemented for torch::optim::OptimizerParamState. \");\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab6ea0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "void OptimizerParamState::serialize(torch::serialize::OutputArchive& archive) const {\n",
    "  throw std::runtime_error(\"void serialize(torch::serialize::OutputArchive& archive) has not been implemented for torch::optim::OptimizerParamState. \");\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3204551",
   "metadata": {},
   "outputs": [],
   "source": [
    "template <typename Derived>\n",
    "class OptimizerCloneableParamState : public OptimizerParamState {\n",
    "  std::unique_ptr<OptimizerParamState> clone() const override {\n",
    "    return std::make_unique<Derived>(static_cast<const Derived&>(*this));\n",
    "  }\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ea9d6",
   "metadata": {},
   "source": [
    "### 2 OptimizerOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf2776a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerOptions {\n",
    " public:\n",
    "  virtual std::unique_ptr<OptimizerOptions> clone() const;\n",
    "  virtual void serialize(torch::serialize::InputArchive& archive);\n",
    "  virtual void serialize(torch::serialize::OutputArchive& archive) const;\n",
    "  virtual ~OptimizerOptions() = default;\n",
    "  virtual double get_lr() const;\n",
    "  virtual void set_lr(const double lr);\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99f95ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template <typename Derived>\n",
    "class OptimizerCloneableOptions : public OptimizerOptions {\n",
    " private:\n",
    "  std::unique_ptr<OptimizerOptions> clone() const override {\n",
    "    return std::make_unique<Derived>(static_cast<const Derived&>(*this));\n",
    "  }\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7abb94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "double OptimizerOptions::get_lr() const {\n",
    "  throw std::runtime_error(\"double get_lr() has not been overidden and implemented in subclass of torch::optim::OptimizerOptions, you must override it in your subclass.\");\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe9d7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "void OptimizerOptions::set_lr(const double lr) {\n",
    "  throw std::runtime_error(\"double set_lr() has not been overidden and implemented in subclass of torch::optim::OptimizerOptions, you must override it in your subclass.\");\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e455383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::unique_ptr<OptimizerOptions> OptimizerOptions::clone() const {\n",
    "  throw std::runtime_error(\"clone() has not been implemented for torch::optim::OptimizerOptions. \");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ba1185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "void OptimizerOptions::serialize(torch::serialize::InputArchive& archive) {\n",
    "  throw std::runtime_error(\"void serialize(torch::serialize::InputArchive& archive) has not been implemented for torch::optim::OptimizerOptions. \");\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbe45078",
   "metadata": {},
   "outputs": [],
   "source": [
    "void OptimizerOptions::serialize(torch::serialize::OutputArchive& archive) const {\n",
    "throw std::runtime_error(\"void serialize(torch::serialize::OutputArchive& archive) has not been implemented for torch::optim::OptimizerOptions. \");\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9617a1",
   "metadata": {},
   "source": [
    "### 3 OptimizerParamGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cc0ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerParamGroup {\n",
    "  protected:\n",
    "  // NOLINTNEXTLINE(cppcoreguidelines-non-private-member-variables-in-classes)\n",
    "  std::vector<torch::Tensor> params_;\n",
    "  // NOLINTNEXTLINE(cppcoreguidelines-non-private-member-variables-in-classes)\n",
    "  std::unique_ptr<OptimizerOptions> options_;\n",
    "\n",
    " public:\n",
    "  // NOTE: In order to store `OptimizerParamGroup` in a `std::vector`, it has to\n",
    "  // be copy-constructible.\n",
    "  OptimizerParamGroup(const OptimizerParamGroup& param_group)\n",
    "      : params_(param_group.params()),\n",
    "        options_(\n",
    "            param_group.has_options() ? param_group.options().clone()\n",
    "                                      : nullptr) {}\n",
    "  OptimizerParamGroup(std::vector<torch::Tensor> params)\n",
    "      : params_(std::move(params)) {}\n",
    "    \n",
    "  OptimizerParamGroup(\n",
    "      std::vector<torch::Tensor> params,\n",
    "      std::unique_ptr<OptimizerOptions> options)\n",
    "      : params_(std::move(params)), options_(std::move(options)) {}\n",
    "\n",
    "  bool has_options() const;\n",
    "  OptimizerOptions& options();\n",
    "  const OptimizerOptions& options() const;\n",
    "  void set_options(std::unique_ptr<OptimizerOptions> options);\n",
    "    \n",
    "  std::vector<torch::Tensor>& params();\n",
    "  const std::vector<torch::Tensor>& params() const{\n",
    "      return params_;\n",
    "    }\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4140c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool OptimizerParamGroup::has_options() const {\n",
    "  return options_ != nullptr;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14dd9da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OptimizerOptions& OptimizerParamGroup::options() {\n",
    "  return *options_.get();\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7eb61526",
   "metadata": {},
   "outputs": [],
   "source": [
    "const OptimizerOptions& OptimizerParamGroup::options() const {\n",
    "  return *options_.get();\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02495c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "void OptimizerParamGroup::set_options(std::unique_ptr<OptimizerOptions> options) {\n",
    "  options_ = std::move(options);\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75fca2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<torch::Tensor>& OptimizerParamGroup::params() {\n",
    "  return params_;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bd90bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "//const std::vector<torch::Tensor>& OptimizerParamGroup::params() const {\n",
    "//  return params_;\n",
    "//};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acdc2c5",
   "metadata": {},
   "source": [
    "### 4 Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3898f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer {\n",
    "  protected:\n",
    "  // NOLINTNEXTLINE(cppcoreguidelines-non-private-member-variables-in-classes)\n",
    "  std::vector<OptimizerParamGroup> param_groups_;\n",
    "  // NOLINTNEXTLINE(cppcoreguidelines-non-private-member-variables-in-classes)\n",
    "  ska::flat_hash_map<std::string, std::unique_ptr<OptimizerParamState>> state_;\n",
    "  // NOLINTNEXTLINE(cppcoreguidelines-non-private-member-variables-in-classes)\n",
    "  std::unique_ptr<OptimizerOptions> defaults_;\n",
    "\n",
    "    \n",
    " public:\n",
    "  // The copy constructor is deleted, because the user should use the\n",
    "  // `state_dict` / `load_state_dict` API to copy an optimizer instead.\n",
    "  Optimizer(const Optimizer& optimizer) = delete;\n",
    "  Optimizer(Optimizer&& optimizer) = default;\n",
    "\n",
    "  explicit Optimizer(\n",
    "      std::vector<OptimizerParamGroup> param_groups,\n",
    "      std::unique_ptr<OptimizerOptions> defaults)\n",
    "      : defaults_(std::move(defaults)) {\n",
    "    for (const auto& param_group : param_groups) {\n",
    "      add_param_group(param_group);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /// Constructs the `Optimizer` from a vector of parameters.\n",
    "  // NOLINTNEXTLINE(performance-move-const-arg)\n",
    "  explicit Optimizer(\n",
    "      std::vector<torch::Tensor> parameters,\n",
    "      std::unique_ptr<OptimizerOptions> defaults)\n",
    "      : Optimizer(\n",
    "            {std::move(OptimizerParamGroup(parameters))},\n",
    "            std::move(defaults)){};\n",
    "\n",
    "  /// Adds the given param_group to the optimizer's param_group list.\n",
    "  void add_param_group(const OptimizerParamGroup& param_group);\n",
    "  /// Adds the given vector of parameters to the optimizer's parameter list.\n",
    "  void add_parameters(const std::vector<torch::Tensor>& parameters);\n",
    "\n",
    "    \n",
    "  virtual ~Optimizer() = default;\n",
    "\n",
    "  using LossClosure = std::function<torch::Tensor()>;\n",
    "  /// A loss function closure, which is expected to return the loss value.\n",
    "  virtual torch::Tensor step(LossClosure closure = nullptr) = 0;\n",
    "\n",
    "\n",
    "  /// Zeros out the gradients of all parameters.\n",
    "  void zero_grad();\n",
    "\n",
    "  /// Provides a reference to the parameters in the first param_group this\n",
    "  /// optimizer holds.\n",
    "  std::vector<torch::Tensor>& parameters();\n",
    "  const std::vector<torch::Tensor>& parameters() const;\n",
    "    \n",
    "  /// Returns the number of parameters referenced by the optimizer.\n",
    "  size_t size() const;\n",
    "\n",
    "  OptimizerOptions& defaults();\n",
    "  const OptimizerOptions& defaults() const;\n",
    "\n",
    "  /// Provides a reference to the param_groups this optimizer holds.\n",
    "  std::vector<OptimizerParamGroup>& param_groups();\n",
    "  /// Provides a const reference to the param_groups this optimizer holds.\n",
    "  const std::vector<OptimizerParamGroup>& param_groups() const;\n",
    "    \n",
    "  /// Provides a reference to the state this optimizer holds\n",
    "  ska::flat_hash_map<std::string, std::unique_ptr<OptimizerParamState>>& state();\n",
    "\n",
    "  /// Serializes the optimizer state into the given `archive`.\n",
    "  virtual void save(torch::serialize::OutputArchive& archive) const;\n",
    "\n",
    "  /// Deserializes the optimizer state from the given `archive`.\n",
    "  virtual void load(torch::serialize::InputArchive& archive);\n",
    "\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28071978",
   "metadata": {},
   "outputs": [],
   "source": [
    "void Optimizer::add_param_group(const OptimizerParamGroup& param_group) {\n",
    "  for (const auto& param : param_group.params()) {\n",
    "    if(param.is_leaf()){\n",
    "        std::cout << \"can't optimize a non-leaf Tensor\" << std::endl;\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  OptimizerParamGroup param_group_(param_group.params());\n",
    "  if (!param_group.has_options()) {\n",
    "    param_group_.set_options(defaults_->clone());\n",
    "  } else {\n",
    "    param_group_.set_options(param_group.options().clone());\n",
    "  }\n",
    "\n",
    "  param_groups_.emplace_back(std::move(param_group_));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1a6c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "void Optimizer::add_parameters(const std::vector<torch::Tensor>& parameters) {\n",
    "  auto& parameters_ = param_groups_[0].params();\n",
    "  parameters_.insert(parameters_.end(), parameters.begin(), parameters.end());\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "709923ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "void Optimizer::zero_grad() {\n",
    "  for (auto& group : param_groups_) {\n",
    "    for (auto& p : group.params()) {\n",
    "      if (p.grad().defined()) {\n",
    "        p.grad().detach_();\n",
    "        p.grad().zero_();\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87651df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<torch::Tensor>& Optimizer::parameters() {\n",
    "  return param_groups_.at(0).params();\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f976baf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1minput_line_49:2:65: \u001b[0m\u001b[0;1;31merror: \u001b[0m\u001b[1mfunction definition is not allowed here\u001b[0m\n",
      " const std::vector<torch::Tensor>& Optimizer::parameters() const{\n",
      "\u001b[0;1;32m                                                                ^\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "Interpreter Error",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Interpreter Error: "
     ]
    }
   ],
   "source": [
    "const std::vector<torch::Tensor>& Optimizer::parameters() const{\n",
    "  return param_groups_.at(0).params();\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23f0cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_t Optimizer::size() const {\n",
    "  size_t count = 0;\n",
    "  for (const auto& group : param_groups_) {\n",
    "    count += group.params().size();\n",
    "  }\n",
    "  return count;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c83b710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OptimizerOptions& Optimizer::defaults() {\n",
    "  return *defaults_.get();\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78ff30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "const OptimizerOptions& Optimizer::defaults() const {\n",
    "  return *defaults_.get();\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c435621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<OptimizerParamGroup>& Optimizer::param_groups() {\n",
    "  return param_groups_;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c236265f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1minput_line_54:2:74: \u001b[0m\u001b[0;1;31merror: \u001b[0m\u001b[1mfunction definition is not allowed here\u001b[0m\n",
      " const std::vector<OptimizerParamGroup>& Optimizer::param_groups() const {\n",
      "\u001b[0;1;32m                                                                         ^\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "Interpreter Error",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Interpreter Error: "
     ]
    }
   ],
   "source": [
    "const std::vector<OptimizerParamGroup>& Optimizer::param_groups() const {\n",
    "  return param_groups_;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dd1e4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1minput_line_55:2:91: \u001b[0m\u001b[0;1;31merror: \u001b[0m\u001b[1mfunction definition is not allowed here\u001b[0m\n",
      "  ...std::unique_ptr<OptimizerParamState>>& Optimizer::state(){\n",
      "\u001b[0;1;32m                                                              ^\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "Interpreter Error",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Interpreter Error: "
     ]
    }
   ],
   "source": [
    "ska::flat_hash_map<std::string, std::unique_ptr<OptimizerParamState>>& Optimizer::state(){\n",
    "  return state_;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb53b298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1minput_line_56:2:104: \u001b[0m\u001b[0;1;31merror: \u001b[0m\u001b[1mfunction definition is not allowed here\u001b[0m\n",
      "  ...std::unique_ptr<OptimizerParamState>>& Optimizer::state() const {\n",
      "\u001b[0;1;32m                                                                     ^\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "Interpreter Error",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Interpreter Error: "
     ]
    }
   ],
   "source": [
    "const ska::flat_hash_map<std::string, std::unique_ptr<OptimizerParamState>>& Optimizer::state() const {\n",
    "  return state_;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8b15759",
   "metadata": {},
   "outputs": [],
   "source": [
    "void Optimizer::save(torch::serialize::OutputArchive& archive) const {};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47861298",
   "metadata": {},
   "outputs": [],
   "source": [
    "void Optimizer::load(torch::serialize::InputArchive& archive) {};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df52a0",
   "metadata": {},
   "source": [
    "### 5 SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define TORCH_ARG(T, name)                                              \\\n",
    " public:                                                                \\\n",
    "  inline auto name(const T& new_##name)->decltype(*this) { /* NOLINT */ \\\n",
    "    this->name##_ = new_##name;                                         \\\n",
    "    return *this;                                                       \\\n",
    "  }                                                                     \\\n",
    "  inline auto name(T&& new_##name)->decltype(*this) { /* NOLINT */      \\\n",
    "    this->name##_ = std::move(new_##name);                              \\\n",
    "    return *this;                                                       \\\n",
    "  }                                                                     \\\n",
    "  inline const T& name() const noexcept { /* NOLINT */                  \\\n",
    "    return this->name##_;                                               \\\n",
    "  }                                                                     \\\n",
    "  inline T& name() noexcept { /* NOLINT */                              \\\n",
    "    return this->name##_;                                               \\\n",
    "  }                                                                     \\\n",
    "                                                                        \\\n",
    " private:                                                               \\\n",
    "  T name##_ /* NOLINT */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a8b4815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1minput_line_60:4:1: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mtreating Unicode character as whitespace [-Wunicode-whitespace]\u001b[0m\n",
      "　public:\n",
      "\u001b[0;1;32m^~\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "class SGDOptions : public OptimizerCloneableOptions<SGDOptions> {\n",
    "  SGDOptions(double lr);\n",
    "  TORCH_ARG(double, lr);\n",
    "\n",
    "　public:\n",
    "   void serialize(torch::serialize::InputArchive& archive) override;\n",
    "   void serialize(torch::serialize::OutputArchive& archive) const override;\n",
    "   ~SGDOptions() override = default;\n",
    "   double get_lr() const override;\n",
    "   void set_lr(const double lr) override;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df556645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1minput_line_63:1:13: \u001b[0m\u001b[0;1;31merror: \u001b[0m\u001b[1mredefinition of 'SGDOptions'\u001b[0m\n",
      "SGDOptions::SGDOptions(double lr) : lr_(lr) {};\n",
      "\u001b[0;1;32m            ^\n",
      "\u001b[0m\u001b[1minput_line_61:1:13: \u001b[0m\u001b[0;1;30mnote: \u001b[0mprevious definition is here\u001b[0m\n",
      "SGDOptions::SGDOptions(double lr) : lr_(lr) {};\n",
      "\u001b[0;1;32m            ^\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "Interpreter Error",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Interpreter Error: "
     ]
    }
   ],
   "source": [
    "SGDOptions::SGDOptions(double lr) : lr_(lr) {};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a216050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "double SGDOptions::get_lr() const {\n",
    "  return lr();\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bad02a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "void SGDOptions::set_lr(const double lr) {\n",
    "  this->lr(lr);\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "905c41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "void SGDOptions::serialize(torch::serialize::OutputArchive& archive) const {\n",
    "  //_TORCH_OPTIM_SERIALIZE_TORCH_ARG(lr);\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ccae5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "void SGDOptions::serialize(torch::serialize::InputArchive& archive) {\n",
    "  //_TORCH_OPTIM_DESERIALIZE_TORCH_ARG(double, lr);\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f90eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDParamState: public OptimizerCloneableParamState<SGDParamState> {\n",
    "  TORCH_ARG(torch::Tensor, momentum_buffer);\n",
    "\n",
    " public:\n",
    "  void serialize(torch::serialize::InputArchive& archive) override;\n",
    "  void serialize(torch::serialize::OutputArchive& archive) const override;\n",
    "  ~SGDParamState() override = default;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11306620",
   "metadata": {},
   "outputs": [],
   "source": [
    "void SGDParamState::serialize(torch::serialize::OutputArchive& archive) const {\n",
    "  //_TORCH_OPTIM_SERIALIZE_TORCH_ARG(momentum_buffer);\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c82191b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "void SGDParamState::serialize(torch::serialize::InputArchive& archive) {\n",
    "  //_TORCH_OPTIM_DESERIALIZE_TORCH_ARG(Tensor, momentum_buffer);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "611efb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD : public Optimizer {\n",
    " public:\n",
    "  explicit SGD(\n",
    "      std::vector<OptimizerParamGroup> param_groups,\n",
    "      SGDOptions defaults)\n",
    "      : Optimizer(\n",
    "            std::move(param_groups),\n",
    "            std::make_unique<SGDOptions>(defaults)) {\n",
    "      }\n",
    "\n",
    "  explicit SGD(\n",
    "      std::vector<torch::Tensor> params,\n",
    "      // NOLINTNEXTLINE(performance-move-const-arg)\n",
    "      SGDOptions defaults)\n",
    "      : SGD({std::move(OptimizerParamGroup(params))}, defaults) {}\n",
    "\n",
    "  torch::Tensor step(LossClosure closure = nullptr) override;\n",
    "\n",
    "  void save(torch::serialize::OutputArchive& archive) const override;\n",
    "  void load(torch::serialize::InputArchive& archive) override;\n",
    "\n",
    " private:\n",
    "  template <typename Self, typename Archive>\n",
    "  static void serialize(Self& self, Archive& archive) {\n",
    "  }\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72fb975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1minput_line_73:6:12: \u001b[0m\u001b[0;1;31merror: \u001b[0m\u001b[1mtype '__cling_N535::Optimizer::LossClosure' (aka 'function<torch::Tensor ()>')\n",
      "      does not provide a call operator\u001b[0m\n",
      "    loss = closure();\n",
      "\u001b[0;1;32m           ^~~~~~~\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "Interpreter Error",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Interpreter Error: "
     ]
    }
   ],
   "source": [
    "torch::Tensor SGD::step(LossClosure closure) {\n",
    "  torch::NoGradGuard no_grad;\n",
    "  torch::Tensor loss = {};\n",
    "  if (closure != nullptr) {\n",
    "    at::AutoGradMode enable_grad(true);\n",
    "    loss = closure();\n",
    "  }\n",
    "  for (auto& group : param_groups_) {\n",
    "    auto& options = static_cast<SGDOptions&>(group.options());\n",
    "\n",
    "    for (auto& p : group.params()) {\n",
    "      if (!p.grad().defined()) {\n",
    "        continue;\n",
    "      }\n",
    "      auto d_p = p.grad().data();\n",
    "      p.data().add_(d_p, -1 * options.lr());\n",
    "    }\n",
    "  }\n",
    "  return loss;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca6eb80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "void SGD::save(torch::serialize::OutputArchive& archive) const {\n",
    "  serialize(*this, archive);\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "46902f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "void SGD::load(torch::serialize::InputArchive& archive) {\n",
    "  torch::IValue pytorch_version;\n",
    "  if (archive.try_read(\"pytorch_version\", pytorch_version)) {\n",
    "    serialize(*this, archive);\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
