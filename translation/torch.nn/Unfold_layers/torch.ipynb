{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3abe6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1b5bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.,  3.],\n",
      "          [ 4.,  5.,  6.,  7.],\n",
      "          [ 8.,  9., 10., 11.]],\n",
      "\n",
      "         [[12., 13., 14., 15.],\n",
      "          [16., 17., 18., 19.],\n",
      "          [20., 21., 22., 23.]]]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.arange(24, dtype=torch.float32).reshape((1, 2, 3, 4))\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922411eb",
   "metadata": {},
   "source": [
    "# nn.Unfold\n",
    "Extracts sliding local blocks from a batched input tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626163bd",
   "metadata": {},
   "source": [
    "torch.nn.Unfold(kernel_size, dilation=1, padding=0, stride=1)\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5257ce1",
   "metadata": {},
   "source": [
    "- example1: kernel_size = (2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac89c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  4.,  5.],\n",
      "         [ 1.,  2.,  5.,  6.],\n",
      "         [ 2.,  3.,  6.,  7.],\n",
      "         [ 4.,  5.,  8.,  9.],\n",
      "         [ 5.,  6.,  9., 10.],\n",
      "         [ 6.,  7., 10., 11.],\n",
      "         [12., 13., 16., 17.],\n",
      "         [13., 14., 17., 18.],\n",
      "         [14., 15., 18., 19.],\n",
      "         [16., 17., 20., 21.],\n",
      "         [17., 18., 21., 22.],\n",
      "         [18., 19., 22., 23.]]])\n",
      "torch.Size([1, 12, 4])\n"
     ]
    }
   ],
   "source": [
    "size = (2, 3)\n",
    "unfold_size23 = nn.Unfold(kernel_size=size)\n",
    "output_size23 = unfold_size23(input)\n",
    "print(output_size23)\n",
    "print(output_size23.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a1df86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- step1 ----------\n",
      "block from input:\n",
      "tensor([[[[0., 1., 2.],\n",
      "          [4., 5., 6.]]]])\n",
      "block in output:\n",
      "tensor([[[0.],\n",
      "         [1.],\n",
      "         [2.],\n",
      "         [4.],\n",
      "         [5.],\n",
      "         [6.]]])\n",
      "\n",
      "---------- step2 ----------\n",
      "block from input:\n",
      "tensor([[[[1., 2., 3.],\n",
      "          [5., 6., 7.]]]])\n",
      "block in output:\n",
      "tensor([[[1.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [5.],\n",
      "         [6.],\n",
      "         [7.]]])\n",
      "\n",
      "---------- step3 ----------\n",
      "block from input:\n",
      "tensor([[[[ 4.,  5.,  6.],\n",
      "          [ 8.,  9., 10.]]]])\n",
      "block in output:\n",
      "tensor([[[ 4.],\n",
      "         [ 5.],\n",
      "         [ 6.],\n",
      "         [ 8.],\n",
      "         [ 9.],\n",
      "         [10.]]])\n",
      "\n",
      "---------- step4 ----------\n",
      "block from input:\n",
      "tensor([[[[ 5.,  6.,  7.],\n",
      "          [ 9., 10., 11.]]]])\n",
      "block in output:\n",
      "tensor([[[ 5.],\n",
      "         [ 6.],\n",
      "         [ 7.],\n",
      "         [ 9.],\n",
      "         [10.],\n",
      "         [11.]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# details in unfolding with kernel_size = (2, 3) \n",
    "print(\"---------- step1 ----------\")\n",
    "print(f\"block from input:\\n{input[:, [0], :size[0], :size[1]]}\")\n",
    "print(f\"block in output:\\n{output_size23[:, :size[0] * size[1], [0]]}\\n\")\n",
    "print(\"---------- step2 ----------\")\n",
    "print(f\"block from input:\\n{input[:, [0], :size[0], 1:size[1] + 1]}\")\n",
    "print(f\"block in output:\\n{output_size23[:, :size[0] * size[1], [1]]}\\n\")\n",
    "print(\"---------- step3 ----------\")\n",
    "print(f\"block from input:\\n{input[:, [0], 1:size[0]+1, :size[1]]}\")\n",
    "print(f\"block in output:\\n{output_size23[:, :size[0] * size[1], [2]]}\\n\")\n",
    "print(\"---------- step4 ----------\")\n",
    "print(f\"block from input:\\n{input[:, [0], 1:size[0]+1, 1:size[1]+1]}\")\n",
    "print(f\"block in output:\\n{output_size23[:, :size[0] * size[1], [3]]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c37602",
   "metadata": {},
   "source": [
    "- example2: kernel_size = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4e413c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.,  3.],\n",
      "          [ 4.,  5.,  6.,  7.],\n",
      "          [ 8.,  9., 10., 11.]],\n",
      "\n",
      "         [[12., 13., 14., 15.],\n",
      "          [16., 17., 18., 19.],\n",
      "          [20., 21., 22., 23.]]]])\n",
      "torch.Size([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(input)\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "173f1505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  4.,  5.,  6.],\n",
      "         [ 1.,  2.,  3.,  5.,  6.,  7.],\n",
      "         [ 4.,  5.,  6.,  8.,  9., 10.],\n",
      "         [ 5.,  6.,  7.,  9., 10., 11.],\n",
      "         [12., 13., 14., 16., 17., 18.],\n",
      "         [13., 14., 15., 17., 18., 19.],\n",
      "         [16., 17., 18., 20., 21., 22.],\n",
      "         [17., 18., 19., 21., 22., 23.]]])\n",
      "torch.Size([1, 8, 6])\n"
     ]
    }
   ],
   "source": [
    "unfold_size22 = nn.Unfold(kernel_size=(2, 2))\n",
    "output_size22 = unfold_size22(input)\n",
    "print(output_size22)\n",
    "print(output_size22.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a6cd79",
   "metadata": {},
   "source": [
    "- example3: kernel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81f40343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_size=2 has the same result as kernel_size=(2, 2): True\n",
      "\n",
      "tensor([[[ 0.,  1.,  2.,  4.,  5.,  6.],\n",
      "         [ 1.,  2.,  3.,  5.,  6.,  7.],\n",
      "         [ 4.,  5.,  6.,  8.,  9., 10.],\n",
      "         [ 5.,  6.,  7.,  9., 10., 11.],\n",
      "         [12., 13., 14., 16., 17., 18.],\n",
      "         [13., 14., 15., 17., 18., 19.],\n",
      "         [16., 17., 18., 20., 21., 22.],\n",
      "         [17., 18., 19., 21., 22., 23.]]])\n",
      "torch.Size([1, 8, 6])\n"
     ]
    }
   ],
   "source": [
    "unfold_size2 = nn.Unfold(kernel_size=2)\n",
    "output_size2 = unfold_size2(input)\n",
    "print(f\"kernel_size=2 has the same result as kernel_size=(2, 2): {(output_size2 == output_size22).all()}\\n\")\n",
    "print(output_size2)\n",
    "print(output_size2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aadefd",
   "metadata": {},
   "source": [
    "# how to reimplement it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a961d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  4.,  5.,  6., 12., 13., 14., 16., 17., 18.]])\n",
      "torch.Size([1, 12])\n",
      "tensor([[ 1.,  2.,  3.,  5.,  6.,  7., 13., 14., 15., 17., 18., 19.]])\n",
      "torch.Size([1, 12])\n",
      "tensor([[ 4.,  5.,  6.,  8.,  9., 10., 16., 17., 18., 20., 21., 22.]])\n",
      "torch.Size([1, 12])\n",
      "tensor([[ 5.,  6.,  7.,  9., 10., 11., 17., 18., 19., 21., 22., 23.]])\n",
      "torch.Size([1, 12])\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "output_manual = []\n",
    "kernel_size = [2, 3]\n",
    "# sliding window approach\n",
    "for i in torch.arange(input.size(2)-kernel_size[0]+1):\n",
    "    for j in torch.arange(input.size(3)-kernel_size[1]+1):\n",
    "        # index current patch\n",
    "        tmp = input[:, :, i:i+kernel_size[0], j:j+kernel_size[1]]\n",
    "        # flatten and keep batch dim\n",
    "        tmp = tmp.contiguous().view(tmp.size(0), -1) # has a shape of [2, 30] afterwards\n",
    "        output_manual.append(tmp)\n",
    "        print(tmp)\n",
    "        print(tmp.shape)\n",
    "    \n",
    "# stack outputs in dim2\n",
    "output_manual = torch.stack(output_manual, dim=2)\n",
    "\n",
    "# compare\n",
    "print((output_manual == output_size23).all())\n",
    "# > tensor(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5598717b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  4.,  5.],\n",
       "         [ 1.,  2.,  5.,  6.],\n",
       "         [ 2.,  3.,  6.,  7.],\n",
       "         [ 4.,  5.,  8.,  9.],\n",
       "         [ 5.,  6.,  9., 10.],\n",
       "         [ 6.,  7., 10., 11.],\n",
       "         [12., 13., 16., 17.],\n",
       "         [13., 14., 17., 18.],\n",
       "         [14., 15., 18., 19.],\n",
       "         [16., 17., 20., 21.],\n",
       "         [17., 18., 21., 22.],\n",
       "         [18., 19., 22., 23.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf6f82",
   "metadata": {},
   "source": [
    "# how to reshape the output of nn.Unfold to behave like a convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9ed40d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[ 0.,  1.,  2.],\n",
      "           [ 4.,  5.,  6.]],\n",
      "\n",
      "          [[ 1.,  2.,  3.],\n",
      "           [ 5.,  6.,  7.]],\n",
      "\n",
      "          [[ 4.,  5.,  6.],\n",
      "           [ 8.,  9., 10.]],\n",
      "\n",
      "          [[ 5.,  6.,  7.],\n",
      "           [ 9., 10., 11.]]],\n",
      "\n",
      "\n",
      "         [[[12., 13., 14.],\n",
      "           [16., 17., 18.]],\n",
      "\n",
      "          [[13., 14., 15.],\n",
      "           [17., 18., 19.]],\n",
      "\n",
      "          [[16., 17., 18.],\n",
      "           [20., 21., 22.]],\n",
      "\n",
      "          [[17., 18., 19.],\n",
      "           [21., 22., 23.]]]]])\n",
      "torch.Size([1, 2, 4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "output_like_convolution = output_size23.reshape((1,2,6,4)).transpose(-1,-2).reshape(1,2,-1,2,3)\n",
    "print(output_like_convolution)\n",
    "print(output_like_convolution.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c876d8",
   "metadata": {},
   "source": [
    "# reference\n",
    "https://discuss.pytorch.org/t/how-nn-unfold-works/137349"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
