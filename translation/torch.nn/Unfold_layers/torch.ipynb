{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3abe6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1b5bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.9708, -0.0897,  0.2432],\n",
      "          [ 0.3745, -0.3273, -0.4943],\n",
      "          [ 0.2818, -0.2199, -2.3114],\n",
      "          [-0.8519,  0.8845,  0.9618]],\n",
      "\n",
      "         [[ 0.6366, -0.9750, -0.0879],\n",
      "          [-1.1110,  0.3916,  0.0232],\n",
      "          [ 0.8274, -0.1599,  1.3982],\n",
      "          [ 1.7917,  0.2212,  0.4457]]]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 2, 4, 3)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922411eb",
   "metadata": {},
   "source": [
    "# nn.Unfold\n",
    "Extracts sliding local blocks from a batched input tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626163bd",
   "metadata": {},
   "source": [
    "torch.nn.Unfold(kernel_size, dilation=1, padding=0, stride=1)\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dce9056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9708, -0.0897,  0.2432,  0.3745, -0.3273, -0.4943],\n",
      "         [ 0.3745, -0.3273, -0.4943,  0.2818, -0.2199, -2.3114],\n",
      "         [ 0.2818, -0.2199, -2.3114, -0.8519,  0.8845,  0.9618],\n",
      "         [ 0.6366, -0.9750, -0.0879, -1.1110,  0.3916,  0.0232],\n",
      "         [-1.1110,  0.3916,  0.0232,  0.8274, -0.1599,  1.3982],\n",
      "         [ 0.8274, -0.1599,  1.3982,  1.7917,  0.2212,  0.4457]]])\n",
      "torch.Size([1, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "# kenel size1: (3, 1)\n",
    "unfold_with_size31 = nn.Unfold(kernel_size=(3, 1))\n",
    "output_with_size31 = unfold_with_size31(input)\n",
    "print(output_with_size31)\n",
    "print(output_with_size31.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af37e879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. the output of torch.Tensor.fold\n",
      "tensor([[[[[ 0.9708,  0.3745,  0.2818],\n",
      "           [-0.0897, -0.3273, -0.2199],\n",
      "           [ 0.2432, -0.4943, -2.3114]],\n",
      "\n",
      "          [[ 0.3745,  0.2818, -0.8519],\n",
      "           [-0.3273, -0.2199,  0.8845],\n",
      "           [-0.4943, -2.3114,  0.9618]]],\n",
      "\n",
      "\n",
      "         [[[ 0.6366, -1.1110,  0.8274],\n",
      "           [-0.9750,  0.3916, -0.1599],\n",
      "           [-0.0879,  0.0232,  1.3982]],\n",
      "\n",
      "          [[-1.1110,  0.8274,  1.7917],\n",
      "           [ 0.3916, -0.1599,  0.2212],\n",
      "           [ 0.0232,  1.3982,  0.4457]]]]])\n",
      "torch.Size([1, 2, 2, 3, 3])\n",
      "\n",
      "2. reshape the output of torch.Tensor.fold to behave like nn.unfold\n",
      "tensor([[[ 0.9708, -0.0897,  0.2432,  0.3745, -0.3273, -0.4943],\n",
      "         [ 0.3745, -0.3273, -0.4943,  0.2818, -0.2199, -2.3114],\n",
      "         [ 0.2818, -0.2199, -2.3114, -0.8519,  0.8845,  0.9618],\n",
      "         [ 0.6366, -0.9750, -0.0879, -1.1110,  0.3916,  0.0232],\n",
      "         [-1.1110,  0.3916,  0.0232,  0.8274, -0.1599,  1.3982],\n",
      "         [ 0.8274, -0.1599,  1.3982,  1.7917,  0.2212,  0.4457]]])\n",
      "torch.Size([1, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "# Alternative method: torch.Tensor.unflod(dimension, step, size)\n",
    "# Note that unfolding happens only in one dimension with torch.Tensor.unfold\n",
    "print(\"1. the output of torch.Tensor.fold\")\n",
    "output_with_unfold = input.unfold(dimension=2, step=1, size=3) # kernel_size = (3, 1) -> dimension=2, size=3\n",
    "print(output_with_unfold) # size=3 means that the sliding window length on the last dimension is 3\n",
    "print(output_with_unfold.shape)\n",
    "print(\"\\n2. reshape the output of torch.Tensor.fold to behave like nn.unfold\")\n",
    "print(output_with_unfold.reshape(1, 2, 6, 3).transpose(2, 3).reshape(1, 6, 6))\n",
    "print(output_with_unfold.reshape(1, 2, 6, 3).transpose(2, 3).reshape(1, 6, 6).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac89c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9708, -0.0897,  0.3745, -0.3273,  0.2818, -0.2199],\n",
      "         [-0.0897,  0.2432, -0.3273, -0.4943, -0.2199, -2.3114],\n",
      "         [ 0.3745, -0.3273,  0.2818, -0.2199, -0.8519,  0.8845],\n",
      "         [-0.3273, -0.4943, -0.2199, -2.3114,  0.8845,  0.9618],\n",
      "         [ 0.6366, -0.9750, -1.1110,  0.3916,  0.8274, -0.1599],\n",
      "         [-0.9750, -0.0879,  0.3916,  0.0232, -0.1599,  1.3982],\n",
      "         [-1.1110,  0.3916,  0.8274, -0.1599,  1.7917,  0.2212],\n",
      "         [ 0.3916,  0.0232, -0.1599,  1.3982,  0.2212,  0.4457]]])\n",
      "torch.Size([1, 8, 6])\n"
     ]
    }
   ],
   "source": [
    "# kenel size2: 2\n",
    "unfold_with_size2 = nn.Unfold(kernel_size=2)\n",
    "output_with_size2 = unfold_with_size2(input)\n",
    "print(output_with_size2)\n",
    "print(output_with_size2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17caf037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9708, -0.0897,  0.3745, -0.3273,  0.2818, -0.2199],\n",
      "         [-0.0897,  0.2432, -0.3273, -0.4943, -0.2199, -2.3114],\n",
      "         [ 0.3745, -0.3273,  0.2818, -0.2199, -0.8519,  0.8845],\n",
      "         [-0.3273, -0.4943, -0.2199, -2.3114,  0.8845,  0.9618],\n",
      "         [ 0.6366, -0.9750, -1.1110,  0.3916,  0.8274, -0.1599],\n",
      "         [-0.9750, -0.0879,  0.3916,  0.0232, -0.1599,  1.3982],\n",
      "         [-1.1110,  0.3916,  0.8274, -0.1599,  1.7917,  0.2212],\n",
      "         [ 0.3916,  0.0232, -0.1599,  1.3982,  0.2212,  0.4457]]])\n",
      "torch.Size([1, 8, 6])\n"
     ]
    }
   ],
   "source": [
    "# kenel size3: (2, 2)\n",
    "# same output as kernel_size=2\n",
    "unfold_with_size22 = nn.Unfold(kernel_size=(2, 2))\n",
    "output_with_size22 = unfold_with_size22(input)\n",
    "print(output_with_size22)\n",
    "print(output_with_size22.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4497f8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9708,  0.3745,  0.2818],\n",
      "         [-0.0897, -0.3273, -0.2199],\n",
      "         [ 0.2432, -0.4943, -2.3114],\n",
      "         [ 0.3745,  0.2818, -0.8519],\n",
      "         [-0.3273, -0.2199,  0.8845],\n",
      "         [-0.4943, -2.3114,  0.9618],\n",
      "         [ 0.6366, -1.1110,  0.8274],\n",
      "         [-0.9750,  0.3916, -0.1599],\n",
      "         [-0.0879,  0.0232,  1.3982],\n",
      "         [-1.1110,  0.8274,  1.7917],\n",
      "         [ 0.3916, -0.1599,  0.2212],\n",
      "         [ 0.0232,  1.3982,  0.4457]]])\n",
      "torch.Size([1, 12, 3])\n"
     ]
    }
   ],
   "source": [
    "# kernel_size4: (2, 3)\n",
    "unfold_with_size23 = nn.Unfold(kernel_size=(2, 3))\n",
    "output_with_size23 = unfold_with_size23(input)\n",
    "print(output_with_size23)\n",
    "print(output_with_size23.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aadefd",
   "metadata": {},
   "source": [
    "# how to reimplement it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a961d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9708, -0.0897,  0.2432,  0.3745, -0.3273, -0.4943,  0.6366, -0.9750,\n",
      "         -0.0879, -1.1110,  0.3916,  0.0232]])\n",
      "torch.Size([1, 12])\n",
      "tensor([[ 0.3745, -0.3273, -0.4943,  0.2818, -0.2199, -2.3114, -1.1110,  0.3916,\n",
      "          0.0232,  0.8274, -0.1599,  1.3982]])\n",
      "torch.Size([1, 12])\n",
      "tensor([[ 0.2818, -0.2199, -2.3114, -0.8519,  0.8845,  0.9618,  0.8274, -0.1599,\n",
      "          1.3982,  1.7917,  0.2212,  0.4457]])\n",
      "torch.Size([1, 12])\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "output_manual = []\n",
    "kernel_size = [2, 3]\n",
    "# sliding window approach\n",
    "for i in torch.arange(input.size(2)-kernel_size[0]+1):\n",
    "    for j in torch.arange(input.size(3)-kernel_size[1]+1):\n",
    "        # index current patch\n",
    "        tmp = input[:, :, i:i+kernel_size[0], j:j+kernel_size[1]]\n",
    "        # flatten and keep batch dim\n",
    "        tmp = tmp.contiguous().view(tmp.size(0), -1) # has a shape of [2, 30] afterwards\n",
    "        output_manual.append(tmp)\n",
    "        print(tmp)\n",
    "        print(tmp.shape)\n",
    "    \n",
    "# stack outputs in dim2\n",
    "output_manual = torch.stack(output_manual, dim=2)\n",
    "\n",
    "# compare\n",
    "print((output_manual == output_with_size23).all())\n",
    "# > tensor(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5598717b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9708,  0.3745,  0.2818],\n",
       "         [-0.0897, -0.3273, -0.2199],\n",
       "         [ 0.2432, -0.4943, -2.3114],\n",
       "         [ 0.3745,  0.2818, -0.8519],\n",
       "         [-0.3273, -0.2199,  0.8845],\n",
       "         [-0.4943, -2.3114,  0.9618],\n",
       "         [ 0.6366, -1.1110,  0.8274],\n",
       "         [-0.9750,  0.3916, -0.1599],\n",
       "         [-0.0879,  0.0232,  1.3982],\n",
       "         [-1.1110,  0.8274,  1.7917],\n",
       "         [ 0.3916, -0.1599,  0.2212],\n",
       "         [ 0.0232,  1.3982,  0.4457]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf6f82",
   "metadata": {},
   "source": [
    "# how to reshape the output of nn.Unfold to behave like a convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9ed40d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[ 0.9708, -0.0897,  0.2432],\n",
      "           [ 0.3745, -0.3273, -0.4943]],\n",
      "\n",
      "          [[ 0.3745, -0.3273, -0.4943],\n",
      "           [ 0.2818, -0.2199, -2.3114]],\n",
      "\n",
      "          [[ 0.2818, -0.2199, -2.3114],\n",
      "           [-0.8519,  0.8845,  0.9618]]],\n",
      "\n",
      "\n",
      "         [[[ 0.6366, -0.9750, -0.0879],\n",
      "           [-1.1110,  0.3916,  0.0232]],\n",
      "\n",
      "          [[-1.1110,  0.3916,  0.0232],\n",
      "           [ 0.8274, -0.1599,  1.3982]],\n",
      "\n",
      "          [[ 0.8274, -0.1599,  1.3982],\n",
      "           [ 1.7917,  0.2212,  0.4457]]]]])\n",
      "torch.Size([1, 2, 3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "output_like_convolution = output_with_size23.reshape((1,2,6,3)).transpose(-1,-2).reshape(1,2,-1,2,3)\n",
    "print(output_like_convolution)\n",
    "print(output_like_convolution.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c876d8",
   "metadata": {},
   "source": [
    "# reference\n",
    "https://discuss.pytorch.org/t/how-nn-unfold-works/137349"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
