{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afaf2f82",
   "metadata": {},
   "source": [
    "# understand attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25572778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pragma cling add_include_path(\"../../../libtorch/include\")\n",
    "#pragma cling add_include_path(\"../../../libtorch/include/torch/csrc/api/include\")\n",
    "#pragma cling add_library_path(\"../../../libtorch/lib\")\n",
    "#pragma cling load(\"libtorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca40b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <tuple>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <cmath>\n",
    "#include <torch/torch.h>\n",
    "#include <torch/script.h>\n",
    "namespace nn = torch::nn;\n",
    "namespace F = torch::nn::functional;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b285fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using torch::indexing::Slice;\n",
    "using torch::indexing::None;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f40b7fc",
   "metadata": {},
   "source": [
    "The interactions between queries (volitional cues) and keys (nonvolitional cues) result in attention pooling. The attention pooling selectively aggregates values (sensory inputs) to produce the output. In this section, we will describe attention pooling in greater detail to give you a high-level view of how attention mechanisms work in practice. Specifically, the Nadaraya-Watson kernel regression model proposed in 1964 is a simple yet complete example for demonstrating machine learning with attention mechanisms\n",
    "\n",
    "# 1 intuition of attention mechanisms¶\n",
    "## generate mock dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84f67bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor f(torch::Tensor x){\n",
    "    return 2 * torch::sin(x) + x.pow(0.8);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35bd74b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "int n_train = 50;\n",
    "torch::Tensor x_train = torch::rand(n_train) * 5;\n",
    "std::tuple<torch::Tensor, torch::Tensor> sorted_tensor = torch::sort(x_train);\n",
    "x_train = std::get<0>(sorted_tensor);\n",
    "    \n",
    "torch::Tensor y_train = f(x_train) + torch::normal(0.0, 0.5, {n_train,});\n",
    "torch::Tensor x_test = torch::arange(0, 5, 0.5);\n",
    "torch::Tensor y_truth = f(x_test);\n",
    "\n",
    "int n_test = x_test.size(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8761ff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10"
     ]
    }
   ],
   "source": [
    "std::cout << n_test;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13132123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns 1 to 10 0.0024  0.0126  0.1656  0.3623  0.4831  0.5598  0.5641  0.6235  0.6449  0.9649\n",
      "\n",
      "Columns 11 to 20 1.0581  1.0602  1.1115  1.2249  1.2952  1.4877  1.5125  1.6455  1.7756  1.7802\n",
      "\n",
      "Columns 21 to 30 2.1077  2.1463  2.1602  2.1610  2.4413  2.5440  2.6271  2.6898  2.7903  2.7922\n",
      "\n",
      "Columns 31 to 40 2.8925  3.1440  3.1508  3.2526  3.3495  3.3830  3.6988  4.0370  4.1022  4.1065\n",
      "\n",
      "Columns 41 to 50 4.1401  4.1482  4.2658  4.2835  4.3629  4.5923  4.6302  4.7272  4.8369  4.8993\n",
      "[ CPUFloatType{1,50} ]"
     ]
    }
   ],
   "source": [
    "std::cout << x_train.index({torch::indexing::None, Slice()});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0c766",
   "metadata": {},
   "source": [
    "## 1.1 Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ad67f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor y_hat = y_train.mean(0).repeat(n_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e483bf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.2468\n",
      " 2.2468\n",
      " 2.2468\n",
      " 2.2468\n",
      " 2.2468\n",
      " 2.2468\n",
      " 2.2468\n",
      " 2.2468\n",
      " 2.2468\n",
      " 2.2468\n",
      "[ CPUFloatType{10} ]\n"
     ]
    }
   ],
   "source": [
    "std::cout << y_hat << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e97abed",
   "metadata": {},
   "source": [
    "## 1.2 Nonparametric Attention Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cde61ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor diff(torch::Tensor queries, torch::Tensor keys){\n",
    "    return queries.reshape({-1, 1}) - keys.reshape({1, -1});\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4158a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor score_function(torch::Tensor queries,torch::Tensor keys){\n",
    "    torch::Tensor query_key_diffs = diff(queries, keys);\n",
    "    torch::Tensor scores = - query_key_diffs.pow(2) / 2;\n",
    "    return scores;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64de1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::tuple<torch::Tensor, torch::Tensor> attention_pool(torch::Tensor scores, torch::Tensor values){\n",
    "    torch::Tensor attention_weights = F::softmax(scores, 1);\n",
    "    torch::Tensor output = torch::matmul(attention_weights, values);\n",
    "    return std::make_tuple(output, attention_weights);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9e4acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::tuple<torch::Tensor, torch::Tensor> output_with_weight = attention_pool(score_function(x_test, x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429ebfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.7523\n",
      " 2.0821\n",
      " 2.3985\n",
      " 2.6507\n",
      " 2.7799\n",
      " 2.7485\n",
      " 2.5707\n",
      " 2.3168\n",
      " 2.0766\n",
      " 1.9056\n",
      "[ CPUFloatType{10} ]\n",
      "Columns 1 to 6 7.5054e-02  7.5048e-02  7.4032e-02  7.0286e-02  6.6786e-02  6.4171e-02\n",
      " 4.8873e-02  4.9121e-02  5.2307e-02  5.4793e-02  5.5307e-02  5.5216e-02\n",
      " 2.8172e-02  2.8461e-02  3.2715e-02  3.7813e-02  4.0545e-02  4.2059e-02\n",
      " 1.3874e-02  1.4088e-02  1.7481e-02  2.2294e-02  2.5393e-02  2.7370e-02\n",
      " 5.6367e-03  5.7535e-03  7.7063e-03  1.0844e-02  1.3120e-02  1.4694e-02\n",
      " 1.8407e-03  1.8886e-03  2.7306e-03  4.2394e-03  5.4489e-03  6.3408e-03\n",
      " 4.7699e-04  4.9192e-04  7.6775e-04  1.3152e-03  1.7957e-03  2.1713e-03\n",
      " 9.8390e-05  1.0199e-04  1.7183e-04  3.2479e-04  4.7106e-04  5.9182e-04\n",
      " 1.6535e-05  1.7229e-05  3.1333e-05  6.5347e-05  1.0068e-04  1.3143e-04\n",
      " 2.3583e-06  2.4700e-06  4.8489e-06  1.1158e-05  1.8262e-05  2.4770e-05\n",
      "\n",
      "Columns 7 to 12 6.4014e-02  6.1796e-02  6.0962e-02  4.7120e-02  4.2879e-02  4.2784e-02\n",
      " 5.5202e-02  5.4895e-02  5.4737e-02  4.9649e-02  4.7337e-02  4.7281e-02\n",
      " 4.2139e-02  4.3168e-02  4.3508e-02  4.6310e-02  4.6260e-02  4.6255e-02\n",
      " 2.7481e-02  2.9001e-02  2.9544e-02  3.6903e-02  3.8623e-02  3.8659e-02\n",
      " 1.4786e-02  1.6074e-02  1.6552e-02  2.4261e-02  2.6604e-02  2.6656e-02\n",
      " 6.3944e-03  7.1610e-03  7.4531e-03  1.2820e-02  1.4729e-02  1.4773e-02\n",
      " 2.1944e-03  2.5315e-03  2.6631e-03  5.3756e-03  6.4707e-03  6.4971e-03\n",
      " 5.9942e-04  7.1237e-04  7.5747e-04  1.7943e-03  2.2629e-03  2.2744e-03\n",
      " 1.3340e-04  1.6332e-04  1.7553e-04  4.8793e-04  6.4473e-04  6.4871e-04\n",
      " 2.5197e-05  3.1778e-05  3.4521e-05  1.1261e-04  1.5590e-04  1.5702e-04\n",
      "\n",
      "Columns 13 to 18 4.0466e-02  3.5448e-02  3.2441e-02  2.4819e-02  2.3913e-02  1.9383e-02\n",
      " 4.5882e-02  4.2535e-02  4.0321e-02  3.3963e-02  3.3132e-02  2.8702e-02\n",
      " 4.6051e-02  4.5182e-02  4.4363e-02  4.1143e-02  4.0636e-02  3.7624e-02\n",
      " 3.9488e-02  4.1002e-02  4.1700e-02  4.2580e-02  4.2580e-02  4.2135e-02\n",
      " 2.7936e-02  3.0697e-02  3.2338e-02  3.6356e-02  3.6810e-02  3.8930e-02\n",
      " 1.5885e-02  1.8472e-02  2.0156e-02  2.4950e-02  2.5576e-02  2.8910e-02\n",
      " 7.1673e-03  8.8210e-03  9.9695e-03  1.3587e-02  1.4102e-02  1.7036e-02\n",
      " 2.5742e-03  3.3529e-03  3.9251e-03  5.8900e-03  6.1893e-03  7.9913e-03\n",
      " 7.5329e-04  1.0383e-03  1.2591e-03  2.0802e-03  2.2132e-03  3.0541e-03\n",
      " 1.8707e-04  2.7290e-04  3.4276e-04  6.2351e-04  6.7163e-04  9.9055e-04\n",
      "\n",
      "Columns 19 to 24 1.5515e-02  1.5390e-02  8.1414e-03  7.5007e-03  7.2791e-03  7.2664e-03\n",
      " 2.4519e-02  2.4377e-02  1.5190e-02  1.4267e-02  1.3942e-02  1.3924e-02\n",
      " 3.4302e-02  3.4181e-02  2.5090e-02  2.4023e-02  2.3640e-02  2.3618e-02\n",
      " 4.0996e-02  4.0945e-02  3.5403e-02  3.4558e-02  3.4245e-02  3.4227e-02\n",
      " 4.0424e-02  4.0465e-02  4.1215e-02  4.1014e-02  4.0926e-02  4.0921e-02\n",
      " 3.2037e-02  3.2143e-02  3.8565e-02  3.9123e-02  3.9312e-02  3.9323e-02\n",
      " 2.0148e-02  2.0261e-02  2.8635e-02  2.9614e-02  2.9966e-02  2.9986e-02\n",
      " 1.0086e-02  1.0166e-02  1.6924e-02  1.7844e-02  1.8182e-02  1.8201e-02\n",
      " 4.1139e-03  4.1557e-03  8.1497e-03  8.7597e-03  8.9879e-03  9.0012e-03\n",
      " 1.4240e-03  1.4417e-03  3.3305e-03  3.6494e-03  3.7707e-03  3.7778e-03\n",
      "\n",
      "Columns 25 to 30 3.8123e-03  2.9515e-03  2.3804e-03  2.0151e-03  1.5299e-03  1.5221e-03\n",
      " 8.4042e-03  6.8492e-03  5.7585e-03  5.0300e-03  4.0157e-03  3.9988e-03\n",
      " 1.6400e-02  1.4070e-02  1.2332e-02  1.1115e-02  9.3307e-03  9.3001e-03\n",
      " 2.7343e-02  2.4693e-02  2.2561e-02  2.0982e-02  1.8522e-02  1.8478e-02\n",
      " 3.7609e-02  3.5754e-02  3.4054e-02  3.2677e-02  3.0334e-02  3.0290e-02\n",
      " 4.1577e-02  4.1609e-02  4.1314e-02  4.0906e-02  3.9930e-02  3.9909e-02\n",
      " 3.6475e-02  3.8425e-02  3.9773e-02  4.0633e-02  4.1709e-02  4.1725e-02\n",
      " 2.5471e-02  2.8246e-02  3.0478e-02  3.2129e-02  3.4680e-02  3.4725e-02\n",
      " 1.4491e-02  1.6917e-02  1.9029e-02  2.0698e-02  2.3493e-02  2.3545e-02\n",
      " 6.9971e-03  8.5986e-03  1.0083e-02  1.1316e-02  1.3506e-02  1.3549e-02\n",
      "\n",
      "Columns 31 to 36 1.1445e-03  5.3569e-04  5.2442e-04  3.7854e-04  2.7491e-04  2.4554e-04\n",
      " 3.1615e-03  1.6781e-03  1.6483e-03  1.2519e-03  9.5435e-04  8.6681e-04\n",
      " 7.7309e-03  4.6533e-03  4.5863e-03  3.6653e-03  2.9328e-03  2.7088e-03\n",
      " 1.6151e-02  1.1024e-02  1.0902e-02  9.1678e-03  7.6997e-03  7.2321e-03\n",
      " 2.7836e-02  2.1547e-02  2.1380e-02  1.8918e-02  1.6677e-02  1.5930e-02\n",
      " 3.8562e-02  3.3849e-02  3.3701e-02  3.1377e-02  2.9034e-02  2.8202e-02\n",
      " 4.2390e-02  4.2196e-02  4.2154e-02  4.1297e-02  4.0110e-02  3.9620e-02\n",
      " 3.7093e-02  4.1871e-02  4.1971e-02  4.3265e-02  4.4108e-02  4.4306e-02\n",
      " 2.6444e-02  3.3851e-02  3.4047e-02  3.6930e-02  3.9518e-02  4.0367e-02\n",
      " 1.6000e-02  2.3226e-02  2.3439e-02  2.6752e-02  3.0047e-02  3.1213e-02\n",
      "\n",
      "Columns 37 to 42 8.0263e-05  2.1698e-05  1.6640e-05  1.6350e-05  1.4235e-05  1.3766e-05\n",
      " 3.3181e-04  1.0623e-04  8.4161e-05  8.2874e-05  7.3377e-05  7.1246e-05\n",
      " 1.2143e-03  4.6036e-04  3.7683e-04  3.7186e-04  3.3482e-04  3.2641e-04\n",
      " 3.7964e-03  1.7045e-03  1.4414e-03  1.4255e-03  1.3052e-03  1.2776e-03\n",
      " 9.7923e-03  5.2064e-03  4.5490e-03  4.5082e-03  4.1978e-03  4.1257e-03\n",
      " 2.0301e-02  1.2783e-02  1.1539e-02  1.1460e-02  1.0851e-02  1.0708e-02\n",
      " 3.3399e-02  2.4903e-02  2.3225e-02  2.3116e-02  2.2260e-02  2.2055e-02\n",
      " 4.3737e-02  3.8620e-02  3.7211e-02  3.7115e-02  3.6346e-02  3.6157e-02\n",
      " 4.6664e-02  4.8796e-02  4.8575e-02  4.8553e-02  4.8353e-02  4.8296e-02\n",
      " 4.2253e-02  5.2323e-02  5.3813e-02  5.3904e-02  5.4591e-02  5.4748e-02\n",
      "\n",
      "Columns 43 to 48 8.3945e-06  7.7833e-06  5.5213e-06  1.9766e-06  1.6600e-06  1.0544e-06\n",
      " 4.6076e-05  4.3101e-05  3.1813e-05  1.2774e-05  1.0932e-05  7.2891e-06\n",
      " 2.2388e-04  2.1128e-04  1.6227e-04  7.3073e-05  6.3735e-05  4.4607e-05\n",
      " 9.2935e-04  8.8484e-04  7.0711e-04  3.5713e-04  3.1744e-04  2.3321e-04\n",
      " 3.1828e-03  3.0573e-03  2.5421e-03  1.4400e-03  1.3044e-03  1.0059e-03\n",
      " 8.7610e-03  8.4903e-03  7.3457e-03  4.6666e-03  4.3081e-03  3.4874e-03\n",
      " 1.9137e-02  1.8710e-02  1.6844e-02  1.2001e-02  1.1291e-02  9.5942e-03\n",
      " 3.3273e-02  3.2821e-02  3.0744e-02  2.4567e-02  2.3555e-02  2.1010e-02\n",
      " 4.7135e-02  4.6907e-02  4.5718e-02  4.0974e-02  4.0036e-02  3.7486e-02\n",
      " 5.6667e-02  5.6893e-02  5.7698e-02  5.7996e-02  5.7752e-02  5.6760e-02\n",
      "\n",
      "Columns 49 to 50 6.2398e-07  4.6045e-07\n",
      " 4.5568e-06  3.4692e-06\n",
      " 2.9459e-05  2.3138e-05\n",
      " 1.6270e-04  1.3185e-04\n",
      " 7.4135e-04  6.1981e-04\n",
      " 2.7151e-03  2.3419e-03\n",
      " 7.8906e-03  7.0220e-03\n",
      " 1.8254e-02  1.6759e-02\n",
      " 3.4404e-02  3.2589e-02\n",
      " 5.5031e-02  5.3780e-02\n",
      "[ CPUFloatType{10,50} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor output = std::get<0>(output_with_weight);\n",
    "torch::Tensor attention_weights = std::get<1>(output_with_weight);\n",
    "\n",
    "std::cout << output << std::endl;\n",
    "std::cout << attention_weights << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d21dc3",
   "metadata": {},
   "source": [
    "## 1.3 Parametric Attention Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86d482dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NWKernelRegressionImpl : public torch::nn::Module {\n",
    "public:\n",
    "    NWKernelRegressionImpl() {\n",
    "        //w = torch::nn::Parameter(torch::rand({1}, torch::requires_grad(true)));\n",
    "        w = torch::rand({1}, torch::requires_grad(true));\n",
    "        register_parameter(\"w\", w);\n",
    "    }\n",
    "\n",
    "    torch::Tensor forward(torch::Tensor queries, torch::Tensor keys, torch::Tensor values) {\n",
    "        // Shape of the output `queries` and `attention_weights`:\n",
    "        // (no. of queries, no. of key-value pairs)\n",
    "        queries = queries.repeat_interleave(keys.size(1)).reshape({-1, keys.size(1)});\n",
    "        auto attention_weights = F::softmax(-1*torch::pow(((queries - keys)*w), 2) / 2, /*dim=*/1);\n",
    "        // attention_weights = rorch::nn::functional::softmax(-1 * torch::pow((queries - keys)* w.item<float>(), 2) / 2, /*dim=*/1);\n",
    "        // Shape of `values`: (no. of queries, no. of key-value pairs)\n",
    "        return torch::bmm(attention_weights.unsqueeze(1),\n",
    "                         values.unsqueeze(-1)).reshape(-1);\n",
    "    }\n",
    "public:\n",
    "    torch::Tensor w; // w parameter\n",
    "};\n",
    "TORCH_MODULE(NWKernelRegression);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5de6c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 49]\n",
      "[50, 49]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor X_tile = x_train.repeat({n_train, 1});\n",
    "\n",
    "// Shape of `Y_tile`: (`n_train`, `n_train`), where each column contains the same training outputs\n",
    "torch::Tensor Y_tile = y_train.repeat({n_train, 1});\n",
    "\n",
    "// Shape of `keys`: ('n_train', 'n_train' - 1)\n",
    "torch::Tensor keys = torch::masked_select(X_tile, (1 - torch::eye(n_train)).to(torch::kBool)).reshape({n_train, -1});\n",
    "std::cout << keys.sizes() << \"\\n\";\n",
    "\n",
    "// Shape of `values`: ('n_train', 'n_train' - 1)\n",
    "torch::Tensor values = torch::masked_select(Y_tile, (1 - torch::eye(n_train)).to(torch::kBool)).reshape({n_train, -1});\n",
    "std::cout << values.sizes() << \"\\n\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8152ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 54.1917\n",
      "epoch: 2, loss: 54.0975\n",
      "epoch: 3, loss: 54.1435\n",
      "epoch: 4, loss: 53.8769\n",
      "epoch: 5, loss: 14.2772\n"
     ]
    }
   ],
   "source": [
    "// Using the squared loss and stochastic gradient descent, we [train the parametric attention model].\n",
    "NWKernelRegression net = NWKernelRegression();\n",
    "torch::nn::MSELoss loss = torch::nn::MSELoss(torch::nn::MSELossOptions(torch::kNone));\n",
    "torch::optim::SGD optimizer = torch::optim::SGD(net->parameters(), 0.5);\n",
    "\n",
    "std::vector<float> v_epoch, v_loss;\n",
    "\n",
    "for( int epoch = 0; epoch < 5; epoch++ ) {\n",
    "    optimizer.zero_grad();\n",
    "    auto l = loss(net->forward(x_train, keys, values), y_train);\n",
    "    l.sum().backward();\n",
    "    optimizer.step();\n",
    "    std::cout << \"epoch: \" << (epoch + 1) << \", loss: \" << l.sum().item<float>() << std::endl;\n",
    "    v_epoch.push_back((epoch + 1)*1.0);\n",
    "    v_loss.push_back(l.sum().item<float>());\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b96668a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4.3752\n",
      "[ CPUFloatType{1} ]\n"
     ]
    }
   ],
   "source": [
    "std::cout << net->w << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e964bbd5",
   "metadata": {},
   "source": [
    "# 2 general framework of attention mechanisms - Attention Scoring Functions\n",
    "In Section 1, we used a Gaussian kernel to model interactions between queries and keys. Treating the exponent of the Gaussian kernel in (11.2.6) as an attention scoring function (or scoring function for short), the results of this function were essentially fed into a softmax operation. As a result, we obtained a probability distribution (attention weights) over values that are paired with keys. In the end, the output of the attention pooling is simply a weighted sum of the values based on these attention weights.\n",
    "\n",
    "At a high level, we can use the above algorithm to instantiate the framework of attention mechanisms in Fig. 11.1.3. Denoting an attention scoring function by , Fig. 11.3.1 illustrates how the output of attention pooling can be computed as a weighted sum of values. Since attention weights are a probability distribution, the weighted sum is essentially a weighted average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41375524",
   "metadata": {},
   "source": [
    "![](https://d2l.ai/_images/attention-output.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8a1b7",
   "metadata": {},
   "source": [
    "### elementary knowledge - Masked Softmax Operation\n",
    "Ａs we just mentioned, a softmax operation is used to output a probability distribution as attention weights. In some cases, not all the values should be fed into attention pooling. For instance, for efficient minibatch processing in Section 10.5, some text sequences are padded with special tokens that do not carry meaning. To get an attention pooling over only meaningful tokens as values, we can specify a valid sequence length (in number of tokens) to filter out those beyond this specified range when computing softmax. In this way, we can implement such a masked softmax operation in the following masked_softmax function, where any value beyond the valid length is masked as zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3d1c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor sequence_mask(torch::Tensor X, torch::Tensor  valid_len, float value) {\n",
    "    //Mask irrelevant entries in sequences.\n",
    "    int64_t maxlen = X.size(1);\n",
    "    auto mask = torch::arange((maxlen), torch::TensorOptions().dtype(torch::kFloat32).device(X.device())).index({torch::indexing::None, Slice()}) < valid_len.index({Slice(), torch::indexing::None});\n",
    "\n",
    "    // (if B - boolean tensor) at::Tensor not_B = torch::ones_like(B) ^ B;\n",
    "    // std::cout << (torch::ones_like(mask) ^ mask).sizes() <<std::endl;\n",
    "    X.index_put_({torch::ones_like(mask) ^ mask}, value);\n",
    "\n",
    "    return X;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7523f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor masked_softmax(torch::Tensor X, torch::Tensor valid_lens) {\n",
    "    // Perform softmax operation by masking elements on the last axis.\n",
    "    // `X`: 3D tensor, `valid_lens`: 1D or 2D tensor\n",
    "    if( ! valid_lens.defined() || (valid_lens.numel() == 0) ) { \t\t\t\t\t\t\t\t// None\n",
    "        return F::softmax(X, /*dim=*/-1);\n",
    "    } else {\n",
    "        auto shape = X.sizes();\n",
    "\n",
    "        if( valid_lens.dim() == 1) {\n",
    "            valid_lens = torch::repeat_interleave(valid_lens, shape[shape.size() - 2]);\n",
    "        } else {\n",
    "            valid_lens = valid_lens.reshape(-1);\n",
    "        }\n",
    "\n",
    "        // On the last axis, replace masked elements with a very large negative value, whose exponentiation outputs 0\n",
    "        //std::cout << X.reshape({-1, shape[shape.size() - 1]}).sizes()  << \"\\n\";\n",
    "        X = sequence_mask(X.reshape({-1, shape[shape.size() - 1]}), valid_lens, /*value=*/ -1e6);\n",
    "\n",
    "        return F::softmax(X.reshape(shape), /*dim=*/-1);\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b663d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,.,.) = \n",
      "  0.6018  0.3982  0.0000  0.0000\n",
      "  0.4276  0.5724  0.0000  0.0000\n",
      "\n",
      "(2,.,.) = \n",
      "  0.3252  0.2519  0.4229  0.0000\n",
      "  0.3284  0.2495  0.4220  0.0000\n",
      "[ CPUFloatType{2,2,4} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor masked_attention_weights = masked_softmax(torch::rand({2, 2, 4}), torch::tensor({2, 3}));\n",
    "std::cout << masked_attention_weights << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41e290a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,.,.) = \n",
      "  1.0000  0.0000  0.0000  0.0000\n",
      "  0.3829  0.2397  0.3774  0.0000\n",
      "\n",
      "(2,.,.) = \n",
      "  0.4128  0.5872  0.0000  0.0000\n",
      "  0.2063  0.2214  0.2841  0.2882\n",
      "[ CPUFloatType{2,2,4} ]\n"
     ]
    }
   ],
   "source": [
    "masked_attention_weights = masked_softmax(torch::rand({2, 2, 4}), torch::tensor({{1, 3}, {2, 4}}));\n",
    "std::cout << masked_attention_weights << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086b92f3",
   "metadata": {},
   "source": [
    "## 2.1 Scaled Dot-Product Attention\n",
    "A more computationally efficient design for the scoring function can be simply dot product. However, the dot product operation requires that both the query and the key have the same vector length, say d. Assume that all the elements of the query and the key are independent random variables with zero mean and unit variance. The dot product of both vectors has zero mean and a variance of . To ensure that the variance of the dot product still remains one regardless of vector length, the scaled dot-product attention scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03631b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttentionImpl : public torch::nn::Module {\n",
    "    public:\n",
    "    // Scaled dot product attention.\n",
    "\tDotProductAttentionImpl(float dropout) {\n",
    "        dpout = torch::nn::Dropout(dropout);\n",
    "        register_module(\"dpout\", dpout);\n",
    "\t}\n",
    "\n",
    "    // Shape of `queries`: (`batch_size`, no. of queries, `d`)\n",
    "    // Shape of `keys`: (`batch_size`, no. of key-value pairs, `d`)\n",
    "    // Shape of `values`: (`batch_size`, no. of key-value pairs, value dimension)\n",
    "    // Shape of `valid_lens`: (`batch_size`,) or (`batch_size`, no. of queries)\n",
    "    torch::Tensor forward(torch::Tensor queries, torch::Tensor keys, torch::Tensor values, torch::Tensor valid_lens) {\n",
    "        int n_shape = (queries.sizes()).size();\n",
    "    \tauto d = queries.sizes()[n_shape - 1];\n",
    "        // Set `transpose_b=True` to swap the last two dimensions of `keys`\n",
    "        auto scores = torch::bmm(queries, keys.transpose(1, 2)) / std::sqrt(d);\n",
    "        attention_weights = masked_softmax(scores, valid_lens);\n",
    "        return torch::bmm(dpout(attention_weights), values);\n",
    "    }\n",
    "    torch::nn::Dropout dpout{nullptr};\n",
    "    torch::Tensor attention_weights;\n",
    "};\n",
    "TORCH_MODULE(DotProductAttention);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a516bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor queries = torch::normal(0, 1, {2, 1, 2});\n",
    "torch::Tensor keys = torch::ones({2, 10, 2});\n",
    "\n",
    "// The two value matrices in the values minibatch are identical\n",
    "torch::Tensor values = torch::arange(40, torch::TensorOptions().dtype(torch::kFloat32)).reshape({1, 10, 4}).repeat({2, 1, 1});\n",
    "\n",
    "torch::Tensor valid_lens = torch::tensor({2, 6});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "693e234f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,.,.) = \n",
      "  0.8010 -0.6466\n",
      "\n",
      "(2,.,.) = \n",
      "  1.2837  0.0655\n",
      "[ CPUFloatType{2,1,2} ]\n"
     ]
    }
   ],
   "source": [
    "std::cout << queries << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1daeee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "\n",
      "(2,.,.) = \n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "  1  1\n",
      "[ CPUFloatType{2,10,2} ]\n"
     ]
    }
   ],
   "source": [
    "std::cout << keys << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8374b23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,.,.) = \n",
      "   0   1   2   3\n",
      "   4   5   6   7\n",
      "   8   9  10  11\n",
      "  12  13  14  15\n",
      "  16  17  18  19\n",
      "  20  21  22  23\n",
      "  24  25  26  27\n",
      "  28  29  30  31\n",
      "  32  33  34  35\n",
      "  36  37  38  39\n",
      "\n",
      "(2,.,.) = \n",
      "   0   1   2   3\n",
      "   4   5   6   7\n",
      "   8   9  10  11\n",
      "  12  13  14  15\n",
      "  16  17  18  19\n",
      "  20  21  22  23\n",
      "  24  25  26  27\n",
      "  28  29  30  31\n",
      "  32  33  34  35\n",
      "  36  37  38  39\n",
      "[ CPUFloatType{2,10,4} ]\n"
     ]
    }
   ],
   "source": [
    "std::cout << values << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b15d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto dattention = DotProductAttention(0.5);\n",
    "dattention->eval();\n",
    "torch::Tensor output = dattention->forward(queries, keys, values, valid_lens);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a7177b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,.,.) = \n",
      "  2  3  4  5\n",
      "\n",
      "(2,.,.) = \n",
      "  10.0000  11.0000  12.0000  13.0000\n",
      "[ CPUFloatType{2,1,4} ]\n",
      "[2, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "std::cout << output << std::endl;\n",
    "std::cout << output.sizes() << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9900a733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,.,.) = \n",
      " Columns 1 to 9  0.5000  0.5000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 10 to 10  0.0000\n",
      "\n",
      "(2,.,.) = \n",
      " Columns 1 to 9  0.1667  0.1667  0.1667  0.1667  0.1667  0.1667  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 10 to 10  0.0000\n",
      "[ CPUFloatType{2,1,10} ]\n",
      "[2, 1, 10]\n"
     ]
    }
   ],
   "source": [
    "std::cout << dattention->attention_weights << std::endl;\n",
    "std::cout << dattention->attention_weights.sizes() << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf696af6",
   "metadata": {},
   "source": [
    "## 2.2 Additive Attention\n",
    "In general, when queries and keys are vectors of different lengths, we can use additive attention as the scoring function. Given a query and a key , the additive attention scoring function\n",
    "\n",
    "a(\\mathbf q, \\mathbf k) = \\mathbf w_v^\\top \\text{tanh}(\\mathbf W_q\\mathbf q + \\mathbf W_k \\mathbf k) \\in \\mathbb{R},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "759e9488",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct AdditiveAttentionImpl : public torch::nn::Module {\n",
    "    public:\n",
    "    //Additive attention\n",
    "    AdditiveAttentionImpl(int64_t key_size, int64_t query_size, int64_t num_hiddens, float dropout) {\n",
    "        W_k = torch::nn::Linear(torch::nn::LinearOptions(key_size, num_hiddens).bias(false));\n",
    "        W_q = torch::nn::Linear(torch::nn::LinearOptions(query_size, num_hiddens).bias(false));\n",
    "        W_v = torch::nn::Linear(torch::nn::LinearOptions(num_hiddens, 1).bias(false));\n",
    "        dpout = torch::nn::Dropout(dropout);\n",
    "        register_module(\"W_k\", W_k);\n",
    "        register_module(\"W_q\", W_q);\n",
    "        register_module(\"W_v\", W_v);\n",
    "        register_module(\"dpout\", dpout);\n",
    "    }\n",
    "\n",
    "    torch::Tensor forward(torch::Tensor queries, torch::Tensor keys, torch::Tensor values, torch::Tensor valid_lens) {\n",
    "        queries = W_q->forward(queries);\n",
    "        keys = W_k->forward(keys);\n",
    "        // After dimension expansion, shape of `queries`: (`batch_size`, no. of\n",
    "        // queries, 1, `num_hiddens`) and shape of `keys`: (`batch_size`, 1,\n",
    "        // no. of key-value pairs, `num_hiddens`). Sum them up with broadcasting\n",
    "\n",
    "        //std::cout << \"queries: \" << queries.sizes() << \"\\n\";\n",
    "        //std::cout << \"keys: \" << keys.sizes() << \"\\n\";\n",
    "        auto features = queries.unsqueeze(2) + keys.unsqueeze(1);\n",
    "        features = torch::tanh(features);\n",
    "\n",
    "        //std::cout << \"features: \" << features.sizes() << \"\\n\";\n",
    "        // There is only one output of `self.w_v`, so we remove the last\n",
    "        // one-dimensional entry from the shape. Shape of `scores`:\n",
    "        // (`batch_size`, no. of queries, no. of key-value pairs)\n",
    "        auto scores = W_v->forward(features).squeeze(-1); //squeeze() 不加参数的，把所有为1的维度都压缩\n",
    "        //std::cout << \"scores: \" << scores.sizes() << \"\\n\";\n",
    "        //std::cout << \"valid_lens: \" << valid_lens.numel() << \"\\n\";\n",
    "\n",
    "        attention_weights = masked_softmax(scores, valid_lens);\n",
    "        //std::cout << \"attention_weights: \" << attention_weights.sizes() << \"\\n\";\n",
    "\n",
    "        // Shape of `values`: (`batch_size`, no. of key-value pairs, value dimension)\n",
    "        return torch::bmm(dpout->forward(attention_weights), values);\n",
    "    }\n",
    "    torch::nn::Linear W_k{nullptr}, W_q{nullptr}, W_v{nullptr};\n",
    "    torch::nn::Dropout dpout{nullptr};\n",
    "    torch::Tensor attention_weights;\n",
    "};\n",
    "\n",
    "TORCH_MODULE(AdditiveAttention);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dda6401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = torch::normal(0, 1, {2, 1, 20});\n",
    "keys = torch::ones({2, 10, 2});\n",
    "\n",
    "// The two value matrices in the values minibatch are identical\n",
    "values = torch::arange(40, torch::TensorOptions().dtype(torch::kFloat32)).reshape({1, 10, 4}).repeat({2, 1, 1});\n",
    "valid_lens = torch::tensor({2, 6});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cc59dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto attention = AdditiveAttention(2, 20, 8, 0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a59b355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention->eval();\n",
    "auto output = attention->forward(queries, keys, values, valid_lens);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ccf73fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,.,.) = \n",
      "  2  3  4  5\n",
      "\n",
      "(2,.,.) = \n",
      "  10.0000  11.0000  12.0000  13.0000\n",
      "[ CPUFloatType{2,1,4} ]\n"
     ]
    }
   ],
   "source": [
    "std::cout << output << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ec4fc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,.,.) = \n",
      " Columns 1 to 9  0.5000  0.5000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 10 to 10  0.0000\n",
      "\n",
      "(2,.,.) = \n",
      " Columns 1 to 9  0.1667  0.1667  0.1667  0.1667  0.1667  0.1667  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 10 to 10  0.0000\n",
      "[ CPUFloatType{2,1,10} ]\n",
      "[2, 1, 10]\n"
     ]
    }
   ],
   "source": [
    "std::cout << attention->attention_weights << std::endl;\n",
    "std::cout << attention->attention_weights.sizes() << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f385b53a",
   "metadata": {},
   "source": [
    "# further reading\n",
    "## multi-head attention\n",
    "In practice, given the same set of queries, keys, and values we may want our model to combine knowledge from different behaviors of the same attention mechanism, such as capturing dependencies of various ranges (e.g., shorter-range vs. longer-range) within a sequence. Thus, it may be beneficial to allow our attention mechanism to jointly use different representation subspaces of queries, keys, and values.\n",
    "\n",
    "To this end, instead of performing a single attention pooling, queries, keys, and values can be transformed with independently learned linear projections. Then these projected queries, keys, and values are fed into attention pooling in parallel. In the end, attention pooling outputs are concatenated and transformed with another learned linear projection to produce the final output. This design is called multi-head attention, where each of the attention pooling outputs is a head [Vaswani et al., 2017]. Using fully connected layers to perform learnable linear transformations, Fig. 11.5.1 describes multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717598c6",
   "metadata": {},
   "source": [
    "![](https://d2l.ai/_images/multi-head-attention.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af5c52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor transpose_qkv(torch::Tensor X, int64_t num_heads) {\n",
    "    // Transposition for parallel computation of multiple attention heads.\n",
    "    // Shape of input `X`:\n",
    "    // (`batch_size`, no. of queries or key-value pairs, `num_hiddens`).\n",
    "    // Shape of output `X`:\n",
    "    // (`batch_size`, no. of queries or key-value pairs, `num_heads`,\n",
    "    // `num_hiddens` / `num_heads`)\n",
    "    X = X.reshape({X.size(0), X.size(1), num_heads, -1});\n",
    "\n",
    "    // Shape of output `X`:\n",
    "    // (`batch_size`, `num_heads`, no. of queries or key-value pairs,\n",
    "    // `num_hiddens` / `num_heads`)\n",
    "    X = X.permute({0, 2, 1, 3});\n",
    "\n",
    "    // Shape of `output`:\n",
    "    // (`batch_size` * `num_heads`, no. of queries or key-value pairs,\n",
    "    // `num_hiddens` / `num_heads`)\n",
    "    return X.reshape({-1, X.size(2), X.size(3)});\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c0137f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor transpose_output(torch::Tensor X, int64_t num_heads) {\n",
    "    // Reverse the operation of `transpose_qkv`.\n",
    "    X = X.reshape({-1, num_heads, X.size(1), X.size(2)});\n",
    "    X = X.permute({0, 2, 1, 3});\n",
    "    return X.reshape({X.size(0), X.size(1), -1});\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02158187",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionImpl : public torch::nn::Module {\n",
    "    public:\n",
    "\tint64_t num_heads;\n",
    "\tDotProductAttention attention{nullptr};\n",
    "\ttorch::nn::Linear W_k{nullptr}, W_q{nullptr}, W_v{nullptr}, W_o{nullptr};\n",
    "\n",
    "    //Multi-head attention\n",
    "\tMultiHeadAttentionImpl(int64_t key_size, int64_t query_size, int64_t value_size, int64_t num_hiddens,\n",
    "                 int64_t n_heads, float dropout, bool bias=false) {\n",
    "\n",
    "        num_heads = n_heads;\n",
    "        attention = DotProductAttention(dropout);\n",
    "        W_q = torch::nn::Linear(torch::nn::LinearOptions(query_size, num_hiddens).bias(bias));\n",
    "        W_k = torch::nn::Linear(torch::nn::LinearOptions(key_size, num_hiddens).bias(bias));\n",
    "        W_v = torch::nn::Linear(torch::nn::LinearOptions(value_size, num_hiddens).bias(bias));\n",
    "        W_o = torch::nn::Linear(torch::nn::LinearOptions(num_hiddens, num_hiddens).bias(bias));\n",
    "        register_module(\"attention\", attention);\n",
    "        register_module(\"W_q\",W_q);\n",
    "        register_module(\"W_k\",W_k);\n",
    "        register_module(\"W_v\",W_v);\n",
    "        register_module(\"W_o\",W_o);\n",
    "\t}\n",
    "\n",
    "    torch::Tensor forward(torch::Tensor queries, torch::Tensor keys, torch::Tensor values, torch::Tensor valid_lens) {\n",
    "        // Shape of `queries`, `keys`, or `values`:\n",
    "        // (`batch_size`, no. of queries or key-value pairs, `num_hiddens`)\n",
    "        // Shape of `valid_lens`:\n",
    "        // (`batch_size`,) or (`batch_size`, no. of queries)\n",
    "        // After transposing, shape of output `queries`, `keys`, or `values`:\n",
    "        // (`batch_size` * `num_heads`, no. of queries or key-value pairs,\n",
    "        // `num_hiddens` / `num_heads`)\n",
    "        queries = transpose_qkv(W_q->forward(queries), num_heads);\n",
    "        keys    = transpose_qkv(W_k->forward(keys), num_heads);\n",
    "        values  = transpose_qkv(W_v->forward(values), num_heads);\n",
    "\n",
    "        if( valid_lens.defined() ) {\n",
    "            // On axis 0, copy the first item (scalar or vector) for\n",
    "            // `num_heads` times, then copy the next item, and so on\n",
    "            valid_lens = torch::repeat_interleave(valid_lens, /*repeats=*/num_heads, /*dim=*/0);\n",
    "        }\n",
    "\n",
    "        // Shape of `output`: (`batch_size` * `num_heads`, no. of queries,\n",
    "        // `num_hiddens` / `num_heads`)\n",
    "        auto output = attention->forward(queries, keys, values, valid_lens);\n",
    "\n",
    "        // Shape of `output_concat`:\n",
    "        // (`batch_size`, no. of queries, `num_hiddens`)\n",
    "        auto output_concat = transpose_output(output, num_heads);\n",
    "        return W_o->forward(output_concat);\n",
    "    }\n",
    "};\n",
    "TORCH_MODULE(MultiHeadAttention);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3dd2a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "int64_t num_hiddens = 10, num_heads = 5;\n",
    "int64_t batch_size = 2, num_queries = 4, num_kvpairs = 6;\n",
    "auto valid_lens = torch::tensor({3, 2});\n",
    "auto X = torch::ones({batch_size, num_queries, num_hiddens});\n",
    "auto Y = torch::ones({batch_size, num_kvpairs, num_hiddens});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bebe8ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 10]\n",
      "__cling_N541::MultiHeadAttentionImpl(\n",
      "  (attention): __cling_N525::DotProductAttentionImpl(\n",
      "    (dpout): torch::nn::Dropout(p=0.5, inplace=false)\n",
      "  )\n",
      "  (W_q): torch::nn::Linear(in_features=10, out_features=10, bias=false)\n",
      "  (W_k): torch::nn::Linear(in_features=10, out_features=10, bias=false)\n",
      "  (W_v): torch::nn::Linear(in_features=10, out_features=10, bias=false)\n",
      "  (W_o): torch::nn::Linear(in_features=10, out_features=10, bias=false)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "auto attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, num_heads, 0.5);\n",
    "attention->eval();\n",
    "std::cout << attention->forward(X, Y, Y, valid_lens).sizes() << std::endl;\n",
    "std::cout << attention << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3794794",
   "metadata": {},
   "source": [
    "## self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afcebdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor output_after_attention = attention ->forward(X, X, X, valid_lens);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61f99ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,.,.) = \n",
      " Columns 1 to 9  0.0065  0.4535 -0.2640 -0.3188  0.0791 -0.4609 -0.1906  0.5901 -0.1081\n",
      "  0.0065  0.4535 -0.2640 -0.3188  0.0791 -0.4609 -0.1906  0.5901 -0.1081\n",
      "  0.0065  0.4535 -0.2640 -0.3188  0.0791 -0.4609 -0.1906  0.5901 -0.1081\n",
      "  0.0065  0.4535 -0.2640 -0.3188  0.0791 -0.4609 -0.1906  0.5901 -0.1081\n",
      "\n",
      "Columns 10 to 10 -0.4416\n",
      " -0.4416\n",
      " -0.4416\n",
      " -0.4416\n",
      "\n",
      "(2,.,.) = \n",
      " Columns 1 to 9  0.0065  0.4535 -0.2640 -0.3188  0.0791 -0.4609 -0.1906  0.5901 -0.1081\n",
      "  0.0065  0.4535 -0.2640 -0.3188  0.0791 -0.4609 -0.1906  0.5901 -0.1081\n",
      "  0.0065  0.4535 -0.2640 -0.3188  0.0791 -0.4609 -0.1906  0.5901 -0.1081\n",
      "  0.0065  0.4535 -0.2640 -0.3188  0.0791 -0.4609 -0.1906  0.5901 -0.1081\n",
      "\n",
      "Columns 10 to 10 -0.4416\n",
      " -0.4416\n",
      " -0.4416\n",
      " -0.4416\n",
      "[ CPUFloatType{2,4,10} ]\n",
      "[2, 4, 10]\n"
     ]
    }
   ],
   "source": [
    "std::cout << output_after_attention << std::endl;\n",
    "std::cout << output_after_attention.sizes() << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "717b0879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,.,.) = \n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "\n",
      "(2,.,.) = \n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "\n",
      "(3,.,.) = \n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "\n",
      "(4,.,.) = \n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "\n",
      "(5,.,.) = \n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "  0.3333  0.3333  0.3333  0.0000\n",
      "\n",
      "(6,.,.) = \n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "\n",
      "(7,.,.) = \n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "\n",
      "(8,.,.) = \n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "\n",
      "(9,.,.) = \n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "\n",
      "(10,.,.) = \n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "  0.5000  0.5000  0.0000  0.0000\n",
      "[ CPUFloatType{10,4,4} ]\n",
      "[10, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "std::cout << attention->attention->attention_weights << std::endl;\n",
    "std::cout << attention->attention->attention_weights.sizes() << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e101a8",
   "metadata": {},
   "source": [
    "# Reference\n",
    "* https://d2l.ai/chapter_attention-mechanisms-and-transformers/index.html\n",
    "* https://github.com/jiamny/Dive_into_deep_learning_with_libtorch/blob/master/src/utils/ch_10_util.h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
