{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "249a0876",
   "metadata": {},
   "source": [
    "# Serialization semantics\n",
    "This note describes how you can save and load PyTorch tensors and module state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84aec3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pragma cling add_include_path(\"../../libtorch/include\")\n",
    "#pragma cling add_include_path(\"../../libtorch/include/torch/csrc/api/include\")\n",
    "#pragma cling add_library_path(\"../../libtorch/lib\")\n",
    "#pragma cling load(\"libtorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2eb7f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <tuple>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <torch/torch.h>\n",
    "#include <torch/script.h>\n",
    "namespace nn = torch::nn;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76faa877",
   "metadata": {},
   "source": [
    "## Saving and loading tensors\n",
    "torch.save() and torch.load() let you easily save and load tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4fc524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      " 2\n",
      "[ CPUFloatType{2} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t = torch::tensor({1., 2.});\n",
    "std::cout << t << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f48b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::save(t, \"./tensor_cxx.pt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4fc680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor loaded_t;\n",
    "torch::load(loaded_t, \"./tensor_cxx.pt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a315939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      " 2\n",
      "[ CPUFloatType{2} ]\n"
     ]
    }
   ],
   "source": [
    "std::cout << loaded_t << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c75c2e6",
   "metadata": {},
   "source": [
    "## Saving and loading torch.nn.Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e62bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto options = nn::BatchNorm1dOptions(/*num_features*/4).eps(0.0).momentum(1.0).affine(true).track_running_stats(true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64479ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn::BatchNorm1d  batch_norm_1d(options);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422d9e76",
   "metadata": {},
   "source": [
    "https://github.com/pytorch/pytorch/blob/master/torch/csrc/api/include/torch/nn/module.h\n",
    "\n",
    "https://github.com/pytorch/pytorch/blob/master/torch/csrc/api/include/torch/ordered_dict.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8163bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::OrderedDict<std::string, torch::Tensor> ordered_parameter_dict = batch_norm_1d ->named_parameters();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fdaa710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key"
     ]
    }
   ],
   "source": [
    "std::cout << ordered_parameter_dict.key_description();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28a94bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[ CPUFloatType{4} ]"
     ]
    }
   ],
   "source": [
    "std::cout << ordered_parameter_dict[\"weight\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8728942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[ CPUFloatType{4} ]"
     ]
    }
   ],
   "source": [
    "std::cout << ordered_parameter_dict[\"bias\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fb92c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "// can not to save ordered_dict\n",
    "//torch::save(ordered_parameter_dict, \"ordered_parameter_dict.pt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ce39e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::OrderedDict<std::string, torch::Tensor> ordered_buffer_dict = batch_norm_1d ->named_buffers();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf1c5c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[ CPUFloatType{4} ]"
     ]
    }
   ],
   "source": [
    "std::cout << ordered_buffer_dict[\"running_mean\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b322a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::save(batch_norm_1d, \"batch_norm_1d.pt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4301be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "// load the model\n",
    "torch::load(batch_norm_1d, \"batch_norm_1d.pt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f102a777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[ CPUFloatType{4} ]\n",
      "bias\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[ CPUFloatType{4} ]\n"
     ]
    }
   ],
   "source": [
    "auto model =  batch_norm_1d;\n",
    "\n",
    "for(auto& p: model->named_parameters()){\n",
    "        //access key\n",
    "        std::cout << p.key() << std::endl;\n",
    "    \n",
    "        // access value\n",
    "        std::cout << p.value() << std::endl;\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93386c4",
   "metadata": {},
   "source": [
    "## load tensor saved from python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4263fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      "[ CPUFloatType{4,4} ]"
     ]
    }
   ],
   "source": [
    "try\n",
    "{\n",
    "    torch::jit::script::Module module = torch::jit::load(\"x.pth\");\n",
    "    c10::IValue iv = module.attr(\"x\");\n",
    "    torch::Tensor ts = iv.toTensor();\n",
    "    std::cout << ts;\n",
    "}catch (const c10::Error& e) {\n",
    "    std::cerr << \"error loading the tensor \" << std::endl;\n",
    "    std::cerr << e.msg() << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d077f3",
   "metadata": {},
   "source": [
    "## load Module saved from python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "130b8f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.1472\n",
      " 0.1472\n",
      "[ CPUFloatType{2,1} ]\n"
     ]
    }
   ],
   "source": [
    "try{\n",
    "    torch::jit::script::Module module;\n",
    "    module = torch::jit::load(\"mymodule.pt\");\n",
    "    \n",
    "    //pprepare input\n",
    "    std::vector<torch::jit::IValue> input_vector;\n",
    "    input_vector.push_back(torch::ones({2,4}));\n",
    "    \n",
    "    // execute the model and turn its output into a tensor\n",
    "    at::Tensor output  = module.forward(input_vector).toTensor();\n",
    "    std::cout << output << std::endl;\n",
    "    \n",
    "} catch (const c10::Error& e){\n",
    "    std::cerr << \"error loading the module \" << std::endl;\n",
    "    std::cerr << e.msg() << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a541e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
