{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99e55ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pragma cling add_include_path(\"../../libtorch/include\")\n",
    "#pragma cling add_include_path(\"../../libtorch/include/torch/csrc/api/include\")\n",
    "#pragma cling add_library_path(\"../../libtorch/lib\")\n",
    "#pragma cling load(\"libtorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce3bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <tuple>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <torch/torch.h>\n",
    "#include <torch/script.h>\n",
    "namespace nn = torch::nn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "559350d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "// for Reproducibility, set random seed. the randomness is same with python version\n",
    "int m_seed = 11;\n",
    "bool m_torch_deterministic = true;\n",
    "srand(m_seed);\n",
    "torch::manual_seed(m_seed);\n",
    "at::globalContext().setDeterministicCuDNN(m_torch_deterministic ? true : false);\n",
    "// https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility\n",
    "at::globalContext().setDeterministicAlgorithms(m_torch_deterministic ? true : false, true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f9558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.7376  1.9459 -0.6995 -1.3023 -0.5133\n",
      "-0.2696  0.2462  0.4839  0.4504 -0.9568\n",
      " 1.5012 -0.3136 -0.2343 -1.0713  0.1648\n",
      "[ CPUFloatType{3,5} ]\n"
     ]
    }
   ],
   "source": [
    "std::cout << torch::randn({3,5}) << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e42ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.1157  0.3834 -0.1234\n",
      " 0.8929 -0.4891 -1.4470\n",
      " 1.1941  0.5462 -2.0750\n",
      "-0.9691 -2.1354 -1.0431\n",
      "[ CPUFloatType{4,3} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor new_x = torch::randn({4,3});\n",
    "std::cout << new_x << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77273cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "std::cout << torch::cuda::is_available() << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bf9bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<char> get_the_bytes(std::string filename) {\n",
    "    std::ifstream input(filename, std::ios::binary);\n",
    "    std::vector<char> bytes(\n",
    "        (std::istreambuf_iterator<char>(input)),\n",
    "        (std::istreambuf_iterator<char>()));\n",
    "\n",
    "    input.close();\n",
    "    return bytes;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20839af",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::string pt_path = \"./none_embeded_model_state_dict.pt\";\n",
    "std::vector<char> f = get_the_bytes(pt_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e6a03ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "void print_vector(const std::vector<char> v){\n",
    "    for(auto x:v){\n",
    "        std::cout << x;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a9822d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_vector(f);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56f40508",
   "metadata": {},
   "outputs": [],
   "source": [
    "c10::Dict<torch::jit::IValue, torch::jit::IValue> weights = torch::pickle_load(f).toGenericDict();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c7f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::NoGradGuard no_grad;\n",
    "for (auto const& w : weights) {\n",
    "    std::string name = w.key().toStringRef();\n",
    "    at::Tensor param = w.value().toTensor();\n",
    "    std::cout << name << std::endl;\n",
    "    std::cout << param << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71f0e6d",
   "metadata": {},
   "source": [
    "~~~\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self,N, M):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(N, M)\n",
    "        self.linear2 = torch.nn.Linear(M, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out0 = self.linear1(input)\n",
    "        out0_relu = torch.nn.functional.relu(out0)\n",
    "        return self.linear2(out0_relu)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "072f61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModuleImpl : public torch::nn::Module {\n",
    "    public:\n",
    "    MyModuleImpl(int64_t N, int64_t M) {\n",
    "    linear1 = register_module(\"linear1\", torch::nn::Linear(N, M));\n",
    "    linear2 = register_module(\"linear2\", torch::nn::Linear(M,1));\n",
    "    //another_bias = register_parameter(\"b\", torch::randn(M));\n",
    "  }\n",
    "    \n",
    "  torch::Tensor forward(torch::Tensor input) {\n",
    "    torch::Tensor out0 = linear1(input);\n",
    "    torch::Tensor out0_relu = torch::nn::functional::relu(out0);  \n",
    "    return linear2(out0_relu);\n",
    "  }\n",
    "    \n",
    "  torch::nn::Linear linear1{nullptr}, linear2{nullptr};\n",
    "  //torch::Tensor another_bias;\n",
    "};\n",
    "TORCH_MODULE(MyModule);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "809da54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModule net{2,3};\n",
    "torch::OrderedDict<std::string, torch::Tensor> ordered_parameter_dict = net->named_parameters();\n",
    "for (const auto& pair : ordered_parameter_dict) {\n",
    "  std::cout << pair.key() << \": \" << pair.value() << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69281207",
   "metadata": {},
   "outputs": [],
   "source": [
    "void init_weights(nn::Module& module) {\n",
    "\ttorch::NoGradGuard noGrad;\n",
    "\tif (auto* linear = module.as<torch::nn::Linear>()) {\n",
    "        nn::init::ones_(linear->weight);\n",
    "        nn::init::zeros_(linear->bias);\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed5f58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "net->apply(init_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a665c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_parameter_dict = net->named_parameters();\n",
    "for (const auto& pair : ordered_parameter_dict) {\n",
    "  std::cout << pair.key() << \": \" << pair.value() << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eebc8a",
   "metadata": {},
   "source": [
    "## none-embeded libtorch model load pretrained params from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73066974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel : public torch::nn::Module {\n",
    "    public:\n",
    "    torch::nn::Linear linear1{nullptr}, linear2{nullptr};\n",
    "    \n",
    "    public:\n",
    "    \n",
    "    PretrainedModel(int64_t N, int64_t M) {\n",
    "        linear1 = register_module(\"linear1\", torch::nn::Linear(N, M));\n",
    "        linear2 = register_module(\"linear2\", torch::nn::Linear(M,1));\n",
    "    }\n",
    "    \n",
    "    \n",
    "    void load_parameters(std::string pt_path){\n",
    "        std::vector<char> f = get_the_bytes(pt_path);\n",
    "        c10::Dict<torch::jit::IValue, torch::jit::IValue> weights = torch::pickle_load(f).toGenericDict();\n",
    "        const torch::OrderedDict<std::string, at::Tensor>& model_params = this->named_parameters();\n",
    "        \n",
    "    \n",
    "        std::vector<std::string> param_names;\n",
    "        for (auto const& w : model_params) {\n",
    "            //std::cout << w.key() << std::endl;\n",
    "            param_names.push_back(w.key());\n",
    "          }\n",
    "\n",
    "        torch::NoGradGuard no_grad;\n",
    "        for (auto const& w : weights) {\n",
    "            std::string name = w.key().toStringRef();\n",
    "            at::Tensor param = w.value().toTensor();\n",
    "            //std::cout << name << std::endl;\n",
    "            //std::cout <<param << std::endl;\n",
    "\n",
    "            if (std::find(param_names.begin(), param_names.end(), name) != param_names.end()){\n",
    "                model_params.find(name)->copy_(param);\n",
    "            } else {\n",
    "                std::cout << name << \" does not exist among model parameters.\" << std::endl;\n",
    "            };\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    torch::Tensor forward(torch::Tensor input) {\n",
    "        torch::Tensor out0 = linear1(input);\n",
    "        torch::Tensor out0_relu = torch::nn::functional::relu(out0);  \n",
    "        return linear2(out0_relu);\n",
    "    }\n",
    "    \n",
    "  //torch::Tensor another_bias;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "260db712",
   "metadata": {},
   "outputs": [],
   "source": [
    "PretrainedModel pretrained_model{2,3};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3880c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (const auto& pair : pretrained_model.named_parameters()) {\n",
    "  std::cout << pair.key() << \": \" << pair.value() << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bee0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.apply(init_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cfc1de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (const auto& pair : pretrained_model.named_parameters()) {\n",
    "  std::cout << pair.key() << \": \" << pair.value() << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1afcf27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.load_parameters(pt_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c2a2561",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (const auto& pair : pretrained_model.named_parameters()) {\n",
    "  std::cout << pair.key() << \": \" << pair.value() << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "152f7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor x = torch::ones({4,2});\n",
    "std::cout << x << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b11188e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor real_output = pretrained_model.forward(x);\n",
    "std::cout << real_output <<std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a7397",
   "metadata": {},
   "source": [
    "# embeded model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df53725",
   "metadata": {},
   "source": [
    "~~~\n",
    "class EmbedModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbedModule, self).__init__()\n",
    "        self.linear0 = torch.nn.Linear(3, 2)\n",
    "        self.model = MyModule(2,3)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output1 = self.linear0(input)\n",
    "        output2 = self.model(output1)\n",
    "        return output2\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ea324aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbededModuleImpl : public torch::nn::Module{\n",
    "    public:\n",
    "    torch::nn::Linear linear0{nullptr};\n",
    "    MyModule model{nullptr};\n",
    "    \n",
    "    public:\n",
    "    EmbededModuleImpl(int64_t P, int64_t N, int64_t M){\n",
    "        linear0 = register_module(\"linear0\", torch::nn::Linear(P,N));\n",
    "        model = register_module(\"model\", MyModule(N, M));\n",
    "        \n",
    "        \n",
    "    }\n",
    "    \n",
    "    torch::Tensor forward(torch::Tensor x){\n",
    "        torch::Tensor output1 = linear0(x);\n",
    "        torch::Tensor output2 = model(output1);\n",
    "        return output2;\n",
    "    }\n",
    "    \n",
    "};\n",
    "TORCH_MODULE(EmbededModule);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d9af542",
   "metadata": {},
   "outputs": [],
   "source": [
    "EmbededModule EmbededModule_ptr{3,2,3};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f209a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (const auto& pair : EmbededModule_ptr->named_parameters()) {\n",
    "  std::cout << pair.key() << \": \" << pair.value() << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd51c47",
   "metadata": {},
   "source": [
    "## 2.2 embeded libtorch model load pretrained params from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ef1fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbededPretrainedModelImpl : public torch::nn::Module {\n",
    "    \n",
    "    public:\n",
    "    torch::nn::Linear linear0{nullptr};\n",
    "    MyModule model{nullptr};\n",
    "    \n",
    "    \n",
    "    public:\n",
    "    \n",
    "    EmbededPretrainedModelImpl(int64_t P, int64_t N, int64_t M){\n",
    "        linear0 = register_module(\"linear0\", torch::nn::Linear(P,N));\n",
    "        model = register_module(\"model\", MyModule(N, M));\n",
    "        \n",
    "        \n",
    "    }\n",
    "    \n",
    "    torch::Tensor forward(torch::Tensor x){\n",
    "        torch::Tensor output1 = linear0(x);\n",
    "        torch::Tensor output2 = model(output1);\n",
    "        return output2;\n",
    "    }\n",
    "    \n",
    "    \n",
    "    void load_parameters(std::string pt_path){\n",
    "        std::vector<char> f = get_the_bytes(pt_path);\n",
    "        c10::Dict<torch::jit::IValue, torch::jit::IValue> weights = torch::pickle_load(f).toGenericDict();\n",
    "        const torch::OrderedDict<std::string, at::Tensor>& model_params = this->named_parameters();\n",
    "        \n",
    "    \n",
    "        std::vector<std::string> param_names;\n",
    "        for (auto const& w : model_params) {\n",
    "            //std::cout << w.key() << std::endl;\n",
    "            param_names.push_back(w.key());\n",
    "          }\n",
    "\n",
    "        torch::NoGradGuard no_grad;\n",
    "        for (auto const& w : weights) {\n",
    "            std::string name = w.key().toStringRef();\n",
    "            at::Tensor param = w.value().toTensor();\n",
    "            //std::cout << name << std::endl;\n",
    "            //std::cout <<param << std::endl;\n",
    "\n",
    "            if (std::find(param_names.begin(), param_names.end(), name) != param_names.end()){\n",
    "                model_params.find(name)->copy_(param);\n",
    "            } else {\n",
    "                std::cout << name << \" does not exist among model parameters.\" << std::endl;\n",
    "            };\n",
    "        }\n",
    "    }\n",
    "   \n",
    "  //torch::Tensor another_bias;\n",
    "};\n",
    "TORCH_MODULE(EmbededPretrainedModel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0175a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EmbededPretrainedModel EmbededPretrainedModel_ptr{3,2,3};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f6b5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (const auto& pair : EmbededPretrainedModel_ptr->named_parameters()) {\n",
    "  std::cout << pair.key() << \": \" << pair.value() << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb3f917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EmbededPretrainedModel_ptr->apply(init_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39780d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (const auto& pair : EmbededPretrainedModel_ptr->named_parameters()) {\n",
    "  std::cout << pair.key() << \": \" << pair.value() << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c18cee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::string embeded_pt_path = \"./embeded_model_state_dict.pt\";\n",
    "EmbededPretrainedModel_ptr->load_parameters(embeded_pt_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5343bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (const auto& pair : EmbededPretrainedModel_ptr->named_parameters()) {\n",
    "  std::cout << pair.key() << \": \" << pair.value() << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03590488",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor output = EmbededPretrainedModel_ptr(new_x);\n",
    "std::cout << output << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff96b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
