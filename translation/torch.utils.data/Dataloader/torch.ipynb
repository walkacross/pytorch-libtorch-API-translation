{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76acbe29",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e62384",
   "metadata": {},
   "source": [
    "At the heart of PyTorch data loading utility is the torch.utils.data.DataLoader class. It represents a Python iterable over a dataset, with support for\n",
    "\n",
    "* map-style and iterable-style datasets,\n",
    "\n",
    "* customizing data loading order,\n",
    "\n",
    "* automatic batching,\n",
    "\n",
    "* single- and multi-process data loading,\n",
    "\n",
    "* automatic memory pinning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5c96c4",
   "metadata": {},
   "source": [
    "These options are configured by the constructor arguments of a DataLoader, which has signature:\n",
    "~~~\n",
    "DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,\n",
    "           batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "           pin_memory=False, drop_last=False, timeout=0,\n",
    "           worker_init_fn=None, *, prefetch_factor=2,\n",
    "           persistent_workers=False)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cca9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "482b4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step1: get your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a96b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.],\n",
      "        [12., 13., 14.],\n",
      "        [15., 16., 17.],\n",
      "        [18., 19., 20.],\n",
      "        [21., 22., 23.],\n",
      "        [24., 25., 26.]])\n",
      "tensor([2, 1, 2, 0, 0, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "sample_size = 9\n",
    "number_features =  3\n",
    "\n",
    "features = torch.arange(sample_size*number_features).reshape(sample_size, number_features) * 1.0\n",
    "label = torch.randint(low=0, high=3, size=(sample_size,))\n",
    "\n",
    "print(features)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d88216be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        assert features.shape[0] == labels.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.features[i], self.labels[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f431c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "286e9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step2: create a dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d504555",
   "metadata": {},
   "source": [
    "## Loading Batched and Non-Batched Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be471a23",
   "metadata": {},
   "source": [
    "DataLoader supports automatically collating individual fetched data samples into batches via arguments batch_size, drop_last, batch_sampler, and collate_fn (which has a default function).\n",
    "\n",
    "### Automatic batching (default)\n",
    "\n",
    "This is the most common case, and corresponds to fetching a minibatch of data and collating them into batched samples, i.e., containing Tensors with one dimension being the batch dimension (usually the first).\n",
    "\n",
    "When batch_size (default 1) is not None, the data loader yields batched samples instead of individual samples. batch_size and drop_last arguments are used to specify how the data loader obtains batches of dataset keys. For map-style datasets, users can alternatively specify batch_sampler, which yields a list of keys at a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d25e11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=2, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a401e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]]), tensor([2, 1])]\n",
      "--------\n",
      "[tensor([[ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]]), tensor([2, 0])]\n",
      "--------\n",
      "[tensor([[12., 13., 14.],\n",
      "        [15., 16., 17.]]), tensor([0, 1])]\n",
      "--------\n",
      "[tensor([[18., 19., 20.],\n",
      "        [21., 22., 23.]]), tensor([1, 1])]\n",
      "--------\n",
      "[tensor([[24., 25., 26.]]), tensor([1])]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for batch_sample in dataloader:\n",
    "    print(batch_sample)\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7933a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### shuffle = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f072433",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=2, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58378901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 1., 2.],\n",
      "        [6., 7., 8.]]), tensor([2, 2])]\n",
      "--------\n",
      "[tensor([[15., 16., 17.],\n",
      "        [21., 22., 23.]]), tensor([1, 1])]\n",
      "--------\n",
      "[tensor([[ 3.,  4.,  5.],\n",
      "        [ 9., 10., 11.]]), tensor([1, 0])]\n",
      "--------\n",
      "[tensor([[18., 19., 20.],\n",
      "        [24., 25., 26.]]), tensor([1, 1])]\n",
      "--------\n",
      "[tensor([[12., 13., 14.]]), tensor([0])]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for batch_sample in dataloader:\n",
    "    print(batch_sample)\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67435926",
   "metadata": {},
   "source": [
    "## set custom sampler\n",
    "\n",
    "A sequential or shuffled sampler will be automatically constructed based on the shuffle argument to a DataLoader. Alternatively, users may use the sampler argument to specify a custom Sampler object that at each time yields the next index/key to fetch.\n",
    "\n",
    "A custom Sampler that yields a list of batch indices at a time can be passed as the batch_sampler argument. Automatic batching can also be enabled via batch_size and drop_last arguments. See the next section for more details on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca43533",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = torch.utils.data.RandomSampler(data_source=dataset, replacement=False, num_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8389141",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=2, shuffle=False, sampler=sampler, drop_last=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f24010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45553e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = torch.utils.data.RandomSampler(data_source=dataset, replacement=True, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e662ff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]]), tensor([2, 0])]\n",
      "--------\n",
      "[tensor([[15., 16., 17.],\n",
      "        [ 0.,  1.,  2.]]), tensor([1, 2])]\n",
      "--------\n",
      "[tensor([[21., 22., 23.]]), tensor([1])]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=2, shuffle=False, sampler=sampler, drop_last=False)\n",
    "for batch_sample in dataloader:\n",
    "    print(batch_sample)\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39667de3",
   "metadata": {},
   "source": [
    "## Working with collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca6fb65",
   "metadata": {},
   "source": [
    "The use of collate_fn is slightly different when automatic batching is enabled or disabled.\n",
    "\n",
    "When automatic batching is disabled, collate_fn is called with each individual data sample, and the output is yielded from the data loader iterator. In this case, the default collate_fn simply converts NumPy arrays in PyTorch tensors.\n",
    "\n",
    "When automatic batching is enabled, collate_fn is called with a list of data samples at each time. It is expected to collate the input samples into a batch for yielding from the data loader iterator. The rest of this section describes the behavior of the default collate_fn (default_collate()).\n",
    "\n",
    "For instance, if each data sample consists of a 3-channel image and an integral class label, i.e., each element of the dataset returns a tuple (image, class_index), the default collate_fn collates a list of such tuples into a single tuple of a batched image tensor and a batched class label Tensor. In particular, the default collate_fn has the following properties:\n",
    "\n",
    "* It always prepends a new dimension as the batch dimension.\n",
    "\n",
    "* It automatically converts NumPy arrays and Python numerical values into PyTorch Tensors.\n",
    "\n",
    "* It preserves the data structure, e.g., if each sample is a dictionary, it outputs a dictionary with the same set of keys but batched Tensors as values (or lists if the values can not be converted into Tensors). Same for list s, tuple s, namedtuple s, etc.\n",
    "\n",
    "Users may use customized collate_fn to achieve custom batching, e.g., collating along a dimension other than the first, padding sequences of various lengths, or adding support for custom data types.\n",
    "\n",
    "If you run into a situation where the outputs of DataLoader have dimensions or type that is different from your expectation, you may want to check your collate_fn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d50035",
   "metadata": {},
   "source": [
    "> basically, the collate_fn receives a list of tuples if your __getitem__ function from a Dataset subclass returns a tuple, or just a normal list if your Dataset subclass returns only one element. Its main objective is to create your batch without spending much time implementing it manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "317d09b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch): \n",
    "    batch_feature_list = []\n",
    "    batch_label_list = []\n",
    "    for sample in batch:\n",
    "        feature, label = sample\n",
    "        new_feature = feature + 0.1\n",
    "        new_label = label + 2\n",
    "        \n",
    "        batch_feature_list.append(new_feature)\n",
    "        batch_label_list.append(new_label)\n",
    "    return [torch.stack(batch_feature_list,0), torch.stack(batch_label_list,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce38b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=2, shuffle=False, drop_last=False, collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bd42c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.1000, 1.1000, 2.1000],\n",
      "        [3.1000, 4.1000, 5.1000]]), tensor([4, 3])]\n",
      "--------\n",
      "[tensor([[ 6.1000,  7.1000,  8.1000],\n",
      "        [ 9.1000, 10.1000, 11.1000]]), tensor([4, 2])]\n",
      "--------\n",
      "[tensor([[12.1000, 13.1000, 14.1000],\n",
      "        [15.1000, 16.1000, 17.1000]]), tensor([2, 3])]\n",
      "--------\n",
      "[tensor([[18.1000, 19.1000, 20.1000],\n",
      "        [21.1000, 22.1000, 23.1000]]), tensor([3, 3])]\n",
      "--------\n",
      "[tensor([[24.1000, 25.1000, 26.1000]]), tensor([3])]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for batch_sample in dataloader:\n",
    "    print(batch_sample)\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a42da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
